{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbbe8813",
      "metadata": {
        "id": "fbbe8813"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import display\n",
        "import datetime\n",
        "import time\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import glob\n",
        "\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.figsize'] = (25,10)\n",
        "mpl.rcParams['axes.grid'] = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2b129d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2b129d5",
        "outputId": "b749122a-28af-4a8b-96b0-88d5f97c83d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 43824 entries, 0 to 43823\n",
            "Data columns (total 7 columns):\n",
            " #   Column             Non-Null Count  Dtype         \n",
            "---  ------             --------------  -----         \n",
            " 0   Time               43824 non-null  datetime64[ns]\n",
            " 1   Ventilation        43824 non-null  float64       \n",
            " 2   Sokets plug        43824 non-null  float64       \n",
            " 3   Lighting           43824 non-null  float64       \n",
            " 4   Other electricity  43824 non-null  float64       \n",
            " 5   Cooling            43824 non-null  float64       \n",
            " 6   Heating            43824 non-null  float64       \n",
            "dtypes: datetime64[ns](1), float64(6)\n",
            "memory usage: 2.3 MB\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/Mohammad-Kaosain-Akbar/NILM-two-years-dataset/main/Data_Greener_all.csv')\n",
        "df['Time']= pd.to_datetime(df['Time'])\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Total = df[\"Ventilation\"] + df[\"Sokets plug\"] + df[\"Lighting\"] + df[\"Other electricity\"] + df[\"Cooling\"] + df[\"Heating\"]\n",
        "# https://www.kite.com/python/answers/how-to-sum-two-columns-in-a-pandas-dataframe-in-python\n",
        "\n",
        "df[\"Total\"] = Total"
      ],
      "metadata": {
        "id": "KukEXy4AmxEa"
      },
      "id": "KukEXy4AmxEa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2DnWpcyos_EF",
        "outputId": "86ba96f7-6137-4d8f-d854-7f6372314cd8"
      },
      "id": "2DnWpcyos_EF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Time  Ventilation  Sokets plug  Lighting  \\\n",
              "0     2017-01-03 13:00:00         27.4         41.8      53.7   \n",
              "1     2017-01-03 14:00:00         21.6         37.5      50.9   \n",
              "2     2017-01-03 15:00:00         18.5         37.4      60.1   \n",
              "3     2017-01-03 16:00:00         29.7         38.0      52.6   \n",
              "4     2017-01-03 17:00:00         16.7         38.1      56.7   \n",
              "...                   ...          ...          ...       ...   \n",
              "43819 2022-01-03 08:00:00         59.3         17.9      16.6   \n",
              "43820 2022-01-03 09:00:00         71.9         20.6      33.1   \n",
              "43821 2022-01-03 10:00:00         90.5         30.9      47.8   \n",
              "43822 2022-01-03 11:00:00         94.0         33.9      52.2   \n",
              "43823 2022-01-03 12:00:00         95.3         28.5      36.3   \n",
              "\n",
              "       Other electricity  Cooling  Heating   Total  \n",
              "0                   89.6    18.60    498.0  729.10  \n",
              "1                   64.6    61.90    500.0  736.50  \n",
              "2                   64.2    16.50    480.0  676.70  \n",
              "3                   43.2    19.80    390.0  573.30  \n",
              "4                   42.4    15.20    373.0  542.10  \n",
              "...                  ...      ...      ...     ...  \n",
              "43819              115.0    12.70    344.0  565.50  \n",
              "43820              149.0    11.90    399.0  685.50  \n",
              "43821              157.0    12.90    397.0  736.10  \n",
              "43822              155.0    15.40    345.0  695.50  \n",
              "43823              107.0     7.88    272.0  546.98  \n",
              "\n",
              "[43824 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05c4d78c-ad95-4208-a92a-dc9d196c8ca5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>Ventilation</th>\n",
              "      <th>Sokets plug</th>\n",
              "      <th>Lighting</th>\n",
              "      <th>Other electricity</th>\n",
              "      <th>Cooling</th>\n",
              "      <th>Heating</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-01-03 13:00:00</td>\n",
              "      <td>27.4</td>\n",
              "      <td>41.8</td>\n",
              "      <td>53.7</td>\n",
              "      <td>89.6</td>\n",
              "      <td>18.60</td>\n",
              "      <td>498.0</td>\n",
              "      <td>729.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-01-03 14:00:00</td>\n",
              "      <td>21.6</td>\n",
              "      <td>37.5</td>\n",
              "      <td>50.9</td>\n",
              "      <td>64.6</td>\n",
              "      <td>61.90</td>\n",
              "      <td>500.0</td>\n",
              "      <td>736.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-01-03 15:00:00</td>\n",
              "      <td>18.5</td>\n",
              "      <td>37.4</td>\n",
              "      <td>60.1</td>\n",
              "      <td>64.2</td>\n",
              "      <td>16.50</td>\n",
              "      <td>480.0</td>\n",
              "      <td>676.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-01-03 16:00:00</td>\n",
              "      <td>29.7</td>\n",
              "      <td>38.0</td>\n",
              "      <td>52.6</td>\n",
              "      <td>43.2</td>\n",
              "      <td>19.80</td>\n",
              "      <td>390.0</td>\n",
              "      <td>573.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-01-03 17:00:00</td>\n",
              "      <td>16.7</td>\n",
              "      <td>38.1</td>\n",
              "      <td>56.7</td>\n",
              "      <td>42.4</td>\n",
              "      <td>15.20</td>\n",
              "      <td>373.0</td>\n",
              "      <td>542.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43819</th>\n",
              "      <td>2022-01-03 08:00:00</td>\n",
              "      <td>59.3</td>\n",
              "      <td>17.9</td>\n",
              "      <td>16.6</td>\n",
              "      <td>115.0</td>\n",
              "      <td>12.70</td>\n",
              "      <td>344.0</td>\n",
              "      <td>565.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43820</th>\n",
              "      <td>2022-01-03 09:00:00</td>\n",
              "      <td>71.9</td>\n",
              "      <td>20.6</td>\n",
              "      <td>33.1</td>\n",
              "      <td>149.0</td>\n",
              "      <td>11.90</td>\n",
              "      <td>399.0</td>\n",
              "      <td>685.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43821</th>\n",
              "      <td>2022-01-03 10:00:00</td>\n",
              "      <td>90.5</td>\n",
              "      <td>30.9</td>\n",
              "      <td>47.8</td>\n",
              "      <td>157.0</td>\n",
              "      <td>12.90</td>\n",
              "      <td>397.0</td>\n",
              "      <td>736.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43822</th>\n",
              "      <td>2022-01-03 11:00:00</td>\n",
              "      <td>94.0</td>\n",
              "      <td>33.9</td>\n",
              "      <td>52.2</td>\n",
              "      <td>155.0</td>\n",
              "      <td>15.40</td>\n",
              "      <td>345.0</td>\n",
              "      <td>695.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43823</th>\n",
              "      <td>2022-01-03 12:00:00</td>\n",
              "      <td>95.3</td>\n",
              "      <td>28.5</td>\n",
              "      <td>36.3</td>\n",
              "      <td>107.0</td>\n",
              "      <td>7.88</td>\n",
              "      <td>272.0</td>\n",
              "      <td>546.98</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43824 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05c4d78c-ad95-4208-a92a-dc9d196c8ca5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05c4d78c-ad95-4208-a92a-dc9d196c8ca5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05c4d78c-ad95-4208-a92a-dc9d196c8ca5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "gFLf6R29tw2x",
        "outputId": "a7cfb750-197a-4d15-d247-5b1a0c6c0a1a"
      },
      "id": "gFLf6R29tw2x",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Ventilation   Sokets plug      Lighting  Other electricity  \\\n",
              "count  43824.000000  43824.000000  43824.000000       43824.000000   \n",
              "mean      32.433825     18.414002     14.316892          87.846242   \n",
              "std       36.211287     27.666459     15.064466          94.951663   \n",
              "min        0.000000      0.000000      0.000000           0.000000   \n",
              "25%        7.000000     11.400000      3.690000          35.800000   \n",
              "50%       14.100000     13.600000      6.500000          79.600000   \n",
              "75%       56.800000     20.100000     22.500000         103.000000   \n",
              "max      793.000000    980.000000    132.000000         971.000000   \n",
              "\n",
              "            Cooling       Heating         Total  \n",
              "count  43824.000000  43824.000000  43824.000000  \n",
              "mean      47.084925     68.994602    269.090489  \n",
              "std       71.422794    113.328362    180.713964  \n",
              "min        0.000000      0.000000      3.130000  \n",
              "25%       13.600000      5.500000    151.377500  \n",
              "50%       21.500000     12.300000    208.180000  \n",
              "75%       51.600000     89.000000    336.000000  \n",
              "max     1641.000000   1120.000000   2037.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9398ef5-364b-42cb-8732-b596e6958532\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ventilation</th>\n",
              "      <th>Sokets plug</th>\n",
              "      <th>Lighting</th>\n",
              "      <th>Other electricity</th>\n",
              "      <th>Cooling</th>\n",
              "      <th>Heating</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>43824.000000</td>\n",
              "      <td>43824.000000</td>\n",
              "      <td>43824.000000</td>\n",
              "      <td>43824.000000</td>\n",
              "      <td>43824.000000</td>\n",
              "      <td>43824.000000</td>\n",
              "      <td>43824.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>32.433825</td>\n",
              "      <td>18.414002</td>\n",
              "      <td>14.316892</td>\n",
              "      <td>87.846242</td>\n",
              "      <td>47.084925</td>\n",
              "      <td>68.994602</td>\n",
              "      <td>269.090489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>36.211287</td>\n",
              "      <td>27.666459</td>\n",
              "      <td>15.064466</td>\n",
              "      <td>94.951663</td>\n",
              "      <td>71.422794</td>\n",
              "      <td>113.328362</td>\n",
              "      <td>180.713964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>11.400000</td>\n",
              "      <td>3.690000</td>\n",
              "      <td>35.800000</td>\n",
              "      <td>13.600000</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>151.377500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>14.100000</td>\n",
              "      <td>13.600000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>79.600000</td>\n",
              "      <td>21.500000</td>\n",
              "      <td>12.300000</td>\n",
              "      <td>208.180000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>56.800000</td>\n",
              "      <td>20.100000</td>\n",
              "      <td>22.500000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>51.600000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>336.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>793.000000</td>\n",
              "      <td>980.000000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>971.000000</td>\n",
              "      <td>1641.000000</td>\n",
              "      <td>1120.000000</td>\n",
              "      <td>2037.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9398ef5-364b-42cb-8732-b596e6958532')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a9398ef5-364b-42cb-8732-b596e6958532 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a9398ef5-364b-42cb-8732-b596e6958532');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df[\"Ventilation\"])):\n",
        "  if df[\"Ventilation\"][i]>20:\n",
        "    df[\"Ventilation\"][i] = 1\n",
        "  else:\n",
        "    df[\"Ventilation\"][i] = 0\n",
        "\n",
        "for i in range(len(df[\"Sokets plug\"])):\n",
        "  if df[\"Sokets plug\"][i]>10:\n",
        "    df[\"Sokets plug\"][i] = 1\n",
        "  else:\n",
        "    df[\"Sokets plug\"][i] = 0\n",
        "\n",
        "for i in range(len(df[\"Lighting\"])):\n",
        "  if df[\"Lighting\"][i]>5:\n",
        "    df[\"Lighting\"][i] = 1\n",
        "  else:\n",
        "    df[\"Lighting\"][i] = 0\n",
        "\n",
        "for i in range(len(df[\"Other electricity\"])):\n",
        "  if df[\"Other electricity\"][i]>50:\n",
        "    df[\"Other electricity\"][i] = 1\n",
        "  else:\n",
        "    df[\"Other electricity\"][i] = 0\n",
        "\n",
        "for i in range(len(df[\"Cooling\"])):\n",
        "  if df[\"Cooling\"][i]>15:\n",
        "    df[\"Cooling\"][i] = 1\n",
        "  else:\n",
        "    df[\"Cooling\"][i] = 0\n",
        "\n",
        "for i in range(len(df[\"Heating\"])):\n",
        "  if df[\"Heating\"][i]>10:\n",
        "    df[\"Heating\"][i] = 1\n",
        "  else:\n",
        "    df[\"Heating\"][i] = 0"
      ],
      "metadata": {
        "id": "4-wwbbH0s1Dd"
      },
      "id": "4-wwbbH0s1Dd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "JD_ERnuv1TmT",
        "outputId": "489cfbd9-fabc-408d-c8dd-2904d3223f22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "id": "JD_ERnuv1TmT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Time  Ventilation  Sokets plug  Lighting  \\\n",
              "0     2017-01-03 13:00:00          1.0          1.0       1.0   \n",
              "1     2017-01-03 14:00:00          1.0          1.0       1.0   \n",
              "2     2017-01-03 15:00:00          0.0          1.0       1.0   \n",
              "3     2017-01-03 16:00:00          1.0          1.0       1.0   \n",
              "4     2017-01-03 17:00:00          0.0          1.0       1.0   \n",
              "...                   ...          ...          ...       ...   \n",
              "43819 2022-01-03 08:00:00          1.0          1.0       1.0   \n",
              "43820 2022-01-03 09:00:00          1.0          1.0       1.0   \n",
              "43821 2022-01-03 10:00:00          1.0          1.0       1.0   \n",
              "43822 2022-01-03 11:00:00          1.0          1.0       1.0   \n",
              "43823 2022-01-03 12:00:00          1.0          1.0       1.0   \n",
              "\n",
              "       Other electricity  Cooling  Heating   Total  \n",
              "0                    1.0      1.0      1.0  729.10  \n",
              "1                    1.0      1.0      1.0  736.50  \n",
              "2                    1.0      1.0      1.0  676.70  \n",
              "3                    0.0      1.0      1.0  573.30  \n",
              "4                    0.0      1.0      1.0  542.10  \n",
              "...                  ...      ...      ...     ...  \n",
              "43819                1.0      0.0      1.0  565.50  \n",
              "43820                1.0      0.0      1.0  685.50  \n",
              "43821                1.0      0.0      1.0  736.10  \n",
              "43822                1.0      1.0      1.0  695.50  \n",
              "43823                1.0      0.0      1.0  546.98  \n",
              "\n",
              "[43824 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ceee2f7-126a-46c6-b56c-5b24d51097ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>Ventilation</th>\n",
              "      <th>Sokets plug</th>\n",
              "      <th>Lighting</th>\n",
              "      <th>Other electricity</th>\n",
              "      <th>Cooling</th>\n",
              "      <th>Heating</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-01-03 13:00:00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>729.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-01-03 14:00:00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>736.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-01-03 15:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>676.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-01-03 16:00:00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>573.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-01-03 17:00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>542.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43819</th>\n",
              "      <td>2022-01-03 08:00:00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>565.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43820</th>\n",
              "      <td>2022-01-03 09:00:00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>685.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43821</th>\n",
              "      <td>2022-01-03 10:00:00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>736.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43822</th>\n",
              "      <td>2022-01-03 11:00:00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>695.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43823</th>\n",
              "      <td>2022-01-03 12:00:00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>546.98</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43824 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ceee2f7-126a-46c6-b56c-5b24d51097ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ceee2f7-126a-46c6-b56c-5b24d51097ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ceee2f7-126a-46c6-b56c-5b24d51097ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8628416d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8628416d",
        "outputId": "f9ce7ab1-e1e4-49f9-a261-3e491768a5ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ventilation counts\n",
            " 0.0    24331\n",
            "1.0    19493\n",
            "Name: Ventilation, dtype: int64\n",
            "Sokets plug counts\n",
            " 1.0    38520\n",
            "0.0     5304\n",
            "Name: Sokets plug, dtype: int64\n",
            "Lighting counts\n",
            " 1.0    26596\n",
            "0.0    17228\n",
            "Name: Lighting, dtype: int64\n",
            "Other electricity counts\n",
            " 1.0    30316\n",
            "0.0    13508\n",
            "Name: Other electricity, dtype: int64\n",
            "Cooling\n",
            " 1.0    30714\n",
            "0.0    13110\n",
            "Name: Cooling, dtype: int64\n",
            "Heating counts\n",
            " 1.0    24047\n",
            "0.0    19777\n",
            "Name: Heating, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Ventilation counts\\n',df['Ventilation'].value_counts())\n",
        "print('Sokets plug counts\\n',df['Sokets plug'].value_counts())\n",
        "print('Lighting counts\\n',df['Lighting'].value_counts())\n",
        "print('Other electricity counts\\n',df['Other electricity'].value_counts())\n",
        "print('Cooling\\n',df['Cooling'].value_counts())\n",
        "print('Heating counts\\n',df['Heating'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2566957e",
      "metadata": {
        "scrolled": true,
        "id": "2566957e"
      },
      "outputs": [],
      "source": [
        "df['Year'] = df['Time'].dt.year\n",
        "df['Month']=df['Time'].dt.month\n",
        "df['Day']=df['Time'].dt.day\n",
        "df['Hour']=df['Time'].dt.hour\n",
        "df.drop('Time', inplace=True, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ylQXgst4k1Yn",
        "outputId": "84d6d2b4-9c9f-41bf-951e-b698579979cd"
      },
      "id": "ylQXgst4k1Yn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Ventilation  Sokets plug  Lighting  Other electricity  Cooling  \\\n",
              "0              1.0          1.0       1.0                1.0      1.0   \n",
              "1              1.0          1.0       1.0                1.0      1.0   \n",
              "2              0.0          1.0       1.0                1.0      1.0   \n",
              "3              1.0          1.0       1.0                0.0      1.0   \n",
              "4              0.0          1.0       1.0                0.0      1.0   \n",
              "...            ...          ...       ...                ...      ...   \n",
              "43819          1.0          1.0       1.0                1.0      0.0   \n",
              "43820          1.0          1.0       1.0                1.0      0.0   \n",
              "43821          1.0          1.0       1.0                1.0      0.0   \n",
              "43822          1.0          1.0       1.0                1.0      1.0   \n",
              "43823          1.0          1.0       1.0                1.0      0.0   \n",
              "\n",
              "       Heating   Total  Year  Month  Day  Hour  \n",
              "0          1.0  729.10  2017      1    3    13  \n",
              "1          1.0  736.50  2017      1    3    14  \n",
              "2          1.0  676.70  2017      1    3    15  \n",
              "3          1.0  573.30  2017      1    3    16  \n",
              "4          1.0  542.10  2017      1    3    17  \n",
              "...        ...     ...   ...    ...  ...   ...  \n",
              "43819      1.0  565.50  2022      1    3     8  \n",
              "43820      1.0  685.50  2022      1    3     9  \n",
              "43821      1.0  736.10  2022      1    3    10  \n",
              "43822      1.0  695.50  2022      1    3    11  \n",
              "43823      1.0  546.98  2022      1    3    12  \n",
              "\n",
              "[43824 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4594bf2-5f91-438f-8391-93be3e7be6ac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ventilation</th>\n",
              "      <th>Sokets plug</th>\n",
              "      <th>Lighting</th>\n",
              "      <th>Other electricity</th>\n",
              "      <th>Cooling</th>\n",
              "      <th>Heating</th>\n",
              "      <th>Total</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>729.10</td>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>736.50</td>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>676.70</td>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>573.30</td>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>542.10</td>\n",
              "      <td>2017</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43819</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>565.50</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43820</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>685.50</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43821</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>736.10</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43822</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>695.50</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43823</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>546.98</td>\n",
              "      <td>2022</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43824 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4594bf2-5f91-438f-8391-93be3e7be6ac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4594bf2-5f91-438f-8391-93be3e7be6ac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4594bf2-5f91-438f-8391-93be3e7be6ac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1_train = df.loc[(df['Year'].isin([2017,2018]))]\n",
        "df1_test = df.loc[(df['Year'].isin([2019]))]\n",
        "\n",
        "print('df_train.shape: ', df1_train.shape)\n",
        "print('df_test.shape: ', df1_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z6I-vytI2r-",
        "outputId": "b8f6fabc-a2ce-4ed2-d1c7-aa602fa7c7cc"
      },
      "id": "8z6I-vytI2r-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_train.shape:  (17459, 11)\n",
            "df_test.shape:  (8760, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdffb980",
      "metadata": {
        "id": "cdffb980"
      },
      "outputs": [],
      "source": [
        "# conda install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe2880a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe2880a5",
        "outputId": "57b34537-0422-44be-a9a5-38f3b9169fae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tcn in /usr/local/lib/python3.7/dist-packages (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tcn) (1.21.6)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-tcn) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (from keras-tcn) (0.16.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.15.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (13.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (0.24.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.44.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (0.5.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (4.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (57.4.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (2.8.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->keras-tcn) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->keras-tcn) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-tcn) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-tcn) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-tcn) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-tcn) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-tcn) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-tcn) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras-tcn) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-tcn) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-tcn) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-tcn) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-tcn) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-tcn) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras-tcn) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras-tcn) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-tcn) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-tcn) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-tcn) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras-tcn) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras-tcn) (3.2.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->keras-tcn) (2.7.1)\n",
            "Requirement already satisfied: keras-tcn in /usr/local/lib/python3.7/dist-packages (3.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tcn\n",
        "!pip install keras-tcn --no-dependencies  # without the dependencies if you already have TF/Numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7fdcf47",
      "metadata": {
        "id": "b7fdcf47"
      },
      "outputs": [],
      "source": [
        "from tcn import TCN\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train1 = df1_train[['Total', 'Year', 'Month', 'Day', 'Hour']].values\n",
        "y_train1 = df1_train[['Ventilation','Sokets plug', 'Lighting', 'Other electricity', 'Cooling', 'Heating']].values\n",
        "X_test1 = df1_test[['Total', 'Year', 'Month', 'Day', 'Hour']].values\n",
        "y_test1 = df1_test[['Ventilation','Sokets plug', 'Lighting', 'Other electricity', 'Cooling', 'Heating']].values\n",
        "print(X_train1.shape, y_train1.shape, X_test1.shape, y_test1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "win6iwkHOQ3n",
        "outputId": "2a3de1d9-bf61-414b-8184-9de37161dba2"
      },
      "id": "win6iwkHOQ3n",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17459, 5) (17459, 6) (8760, 5) (8760, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import StandardScaler\n",
        "# sc = StandardScaler()\n",
        "# X_train1 = sc.fit_transform(X_train1)\n",
        "# X_test1=sc.fit_transform(X_test1)"
      ],
      "metadata": {
        "id": "4YHLBZKQXbi-"
      },
      "id": "4YHLBZKQXbi-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82be13a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82be13a6",
        "outputId": "18af7933-19df-481b-a4fa-fdd72aeefc11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " tcn_2 (TCN)                 (None, 32)                34336     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 300)               9900      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 500)               150500    \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 6)                 3006      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 197,742\n",
            "Trainable params: 197,742\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(TCN(\n",
        "      input_shape = (5,1),\n",
        "      nb_filters=32,\n",
        "      dilations=(1, 2, 4, 8, 16, 32),\n",
        "      activation='relu',\n",
        "      padding='causal',       \n",
        "))\n",
        "model.add(Dense(300, input_dim=300, kernel_initializer='he_uniform', activation='relu'))\n",
        "model.add(Dense(500, input_dim=500, kernel_initializer='he_uniform', activation='sigmoid'))\n",
        "model.add(Dense(6, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Sequential()\n",
        "# model.add(Dense(12, input_dim=5, activation='relu'))\n",
        "# model.add(Dense(8, activation='relu'))\n",
        "# model.add(Dense(6, activation='sigmoid'))\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "qvrBpEpY5Zco"
      },
      "id": "qvrBpEpY5Zco",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train1, y_train1, epochs=50, batch_size=16,validation_split=0.15,validation_data=None,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_MepdeEPK_X",
        "outputId": "7b829355-91ee-47d1-a684-323a12c893cf"
      },
      "id": "l_MepdeEPK_X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "928/928 [==============================] - 68s 14ms/step - loss: 0.4853 - accuracy: 0.2150 - val_loss: 0.8857 - val_accuracy: 0.7679\n",
            "Epoch 2/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4844 - accuracy: 0.2057 - val_loss: 0.9726 - val_accuracy: 0.0011\n",
            "Epoch 3/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4849 - accuracy: 0.2327 - val_loss: 0.8727 - val_accuracy: 0.7679\n",
            "Epoch 4/50\n",
            "928/928 [==============================] - 14s 15ms/step - loss: 0.4849 - accuracy: 0.2181 - val_loss: 0.9591 - val_accuracy: 7.6365e-04\n",
            "Epoch 5/50\n",
            "928/928 [==============================] - 14s 15ms/step - loss: 0.4844 - accuracy: 0.2184 - val_loss: 0.8815 - val_accuracy: 0.7679\n",
            "Epoch 6/50\n",
            "928/928 [==============================] - 14s 15ms/step - loss: 0.4850 - accuracy: 0.2076 - val_loss: 0.9709 - val_accuracy: 0.7679\n",
            "Epoch 7/50\n",
            "928/928 [==============================] - 13s 13ms/step - loss: 0.4851 - accuracy: 0.2206 - val_loss: 0.8901 - val_accuracy: 0.7679\n",
            "Epoch 8/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4857 - accuracy: 0.2396 - val_loss: 0.8515 - val_accuracy: 0.7679\n",
            "Epoch 9/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4845 - accuracy: 0.2445 - val_loss: 0.9120 - val_accuracy: 0.7679\n",
            "Epoch 10/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4851 - accuracy: 0.2489 - val_loss: 0.9051 - val_accuracy: 0.7679\n",
            "Epoch 11/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4846 - accuracy: 0.2209 - val_loss: 0.8681 - val_accuracy: 0.7679\n",
            "Epoch 12/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4839 - accuracy: 0.2178 - val_loss: 0.9691 - val_accuracy: 0.0011\n",
            "Epoch 13/50\n",
            "928/928 [==============================] - 14s 15ms/step - loss: 0.4847 - accuracy: 0.2086 - val_loss: 0.9108 - val_accuracy: 0.7679\n",
            "Epoch 14/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4850 - accuracy: 0.1982 - val_loss: 0.9113 - val_accuracy: 0.7679\n",
            "Epoch 15/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4845 - accuracy: 0.2276 - val_loss: 0.9806 - val_accuracy: 0.0011\n",
            "Epoch 16/50\n",
            "928/928 [==============================] - 14s 15ms/step - loss: 0.4850 - accuracy: 0.2186 - val_loss: 0.9092 - val_accuracy: 7.6365e-04\n",
            "Epoch 17/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4848 - accuracy: 0.2179 - val_loss: 0.9358 - val_accuracy: 7.6365e-04\n",
            "Epoch 18/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4845 - accuracy: 0.2393 - val_loss: 0.9572 - val_accuracy: 7.6365e-04\n",
            "Epoch 19/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4849 - accuracy: 0.2156 - val_loss: 0.9540 - val_accuracy: 7.6365e-04\n",
            "Epoch 20/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4847 - accuracy: 0.2215 - val_loss: 0.8666 - val_accuracy: 7.6365e-04\n",
            "Epoch 21/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4845 - accuracy: 0.2255 - val_loss: 0.9829 - val_accuracy: 7.6365e-04\n",
            "Epoch 22/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4847 - accuracy: 0.2067 - val_loss: 1.0218 - val_accuracy: 7.6365e-04\n",
            "Epoch 23/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4839 - accuracy: 0.2268 - val_loss: 0.9076 - val_accuracy: 0.7679\n",
            "Epoch 24/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4837 - accuracy: 0.2216 - val_loss: 0.8866 - val_accuracy: 0.7679\n",
            "Epoch 25/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4854 - accuracy: 0.2497 - val_loss: 0.9162 - val_accuracy: 7.6365e-04\n",
            "Epoch 26/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4844 - accuracy: 0.2204 - val_loss: 0.8184 - val_accuracy: 0.7679\n",
            "Epoch 27/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4845 - accuracy: 0.2140 - val_loss: 0.9525 - val_accuracy: 7.6365e-04\n",
            "Epoch 28/50\n",
            "928/928 [==============================] - 12s 13ms/step - loss: 0.4855 - accuracy: 0.2212 - val_loss: 0.9182 - val_accuracy: 0.7679\n",
            "Epoch 29/50\n",
            "928/928 [==============================] - 14s 15ms/step - loss: 0.4851 - accuracy: 0.2014 - val_loss: 0.9028 - val_accuracy: 7.6365e-04\n",
            "Epoch 30/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4849 - accuracy: 0.2146 - val_loss: 0.9468 - val_accuracy: 0.0011\n",
            "Epoch 31/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4847 - accuracy: 0.2153 - val_loss: 0.9389 - val_accuracy: 7.6365e-04\n",
            "Epoch 32/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4844 - accuracy: 0.2227 - val_loss: 0.9509 - val_accuracy: 0.7679\n",
            "Epoch 33/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4852 - accuracy: 0.2307 - val_loss: 0.9391 - val_accuracy: 0.7679\n",
            "Epoch 34/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4850 - accuracy: 0.2459 - val_loss: 0.9848 - val_accuracy: 7.6365e-04\n",
            "Epoch 35/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4851 - accuracy: 0.2082 - val_loss: 0.9235 - val_accuracy: 7.6365e-04\n",
            "Epoch 36/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4844 - accuracy: 0.2181 - val_loss: 0.9178 - val_accuracy: 0.7679\n",
            "Epoch 37/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4845 - accuracy: 0.2276 - val_loss: 0.9314 - val_accuracy: 7.6365e-04\n",
            "Epoch 38/50\n",
            "928/928 [==============================] - 14s 15ms/step - loss: 0.4858 - accuracy: 0.2108 - val_loss: 0.8665 - val_accuracy: 0.7679\n",
            "Epoch 39/50\n",
            "928/928 [==============================] - 14s 15ms/step - loss: 0.4845 - accuracy: 0.2248 - val_loss: 0.9382 - val_accuracy: 0.7679\n",
            "Epoch 40/50\n",
            "928/928 [==============================] - 14s 15ms/step - loss: 0.4852 - accuracy: 0.2394 - val_loss: 0.9181 - val_accuracy: 7.6365e-04\n",
            "Epoch 41/50\n",
            "928/928 [==============================] - 14s 15ms/step - loss: 0.4841 - accuracy: 0.2327 - val_loss: 0.9250 - val_accuracy: 7.6365e-04\n",
            "Epoch 42/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4848 - accuracy: 0.2352 - val_loss: 0.8498 - val_accuracy: 0.7679\n",
            "Epoch 43/50\n",
            "928/928 [==============================] - 14s 15ms/step - loss: 0.4842 - accuracy: 0.2350 - val_loss: 0.9297 - val_accuracy: 7.6365e-04\n",
            "Epoch 44/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4846 - accuracy: 0.2089 - val_loss: 0.9132 - val_accuracy: 0.7679\n",
            "Epoch 45/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4845 - accuracy: 0.2215 - val_loss: 0.9586 - val_accuracy: 0.7679\n",
            "Epoch 46/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4848 - accuracy: 0.2160 - val_loss: 0.9009 - val_accuracy: 7.6365e-04\n",
            "Epoch 47/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4841 - accuracy: 0.2067 - val_loss: 0.8992 - val_accuracy: 7.6365e-04\n",
            "Epoch 48/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4847 - accuracy: 0.2222 - val_loss: 0.8386 - val_accuracy: 0.7679\n",
            "Epoch 49/50\n",
            "928/928 [==============================] - 12s 13ms/step - loss: 0.4843 - accuracy: 0.2355 - val_loss: 0.9257 - val_accuracy: 7.6365e-04\n",
            "Epoch 50/50\n",
            "928/928 [==============================] - 13s 14ms/step - loss: 0.4850 - accuracy: 0.2051 - val_loss: 0.9414 - val_accuracy: 7.6365e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6fb4b10a10>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pred = model.predict(X_test1)\n"
      ],
      "metadata": {
        "id": "2AUeWo52U0dZ"
      },
      "id": "2AUeWo52U0dZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = (model.predict(X_test1) > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "Jy0mg1CL70vk"
      },
      "id": "Jy0mg1CL70vk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxMYkhtX5H4Z",
        "outputId": "a93e476c-3501-4c09-d545-3f18e83d2742"
      },
      "id": "zxMYkhtX5H4Z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1, 1, 1, 1],\n",
              "       [0, 1, 1, 1, 1, 1],\n",
              "       [0, 1, 1, 1, 1, 1],\n",
              "       ...,\n",
              "       [0, 1, 1, 1, 1, 1],\n",
              "       [0, 1, 1, 1, 1, 1],\n",
              "       [0, 1, 1, 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "\tprint('%s => %s (expected %s)' % (X_test1[i].tolist(), predictions[i].tolist(), y_test1[i].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri5IT6XF79G_",
        "outputId": "183b0d12-af39-400c-8708-f0b36dbac6ac"
      },
      "id": "Ri5IT6XF79G_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[282.28, 2019.0, 1.0, 1.0, 0.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[248.73000000000002, 2019.0, 1.0, 1.0, 1.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[266.34000000000003, 2019.0, 1.0, 1.0, 2.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[264.995, 2019.0, 1.0, 1.0, 3.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[299.005, 2019.0, 1.0, 1.0, 4.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[248.775, 2019.0, 1.0, 1.0, 5.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[282.33, 2019.0, 1.0, 1.0, 6.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[283.04, 2019.0, 1.0, 1.0, 7.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[253.05, 2019.0, 1.0, 1.0, 8.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[271.79, 2019.0, 1.0, 1.0, 9.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[302.79, 2019.0, 1.0, 1.0, 10.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 0.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[236.27, 2019.0, 1.0, 1.0, 11.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[251.84, 2019.0, 1.0, 1.0, 12.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[267.79, 2019.0, 1.0, 1.0, 13.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[218.53, 2019.0, 1.0, 1.0, 14.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[217.31, 2019.0, 1.0, 1.0, 15.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[269.22, 2019.0, 1.0, 1.0, 16.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[219.01, 2019.0, 1.0, 1.0, 17.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[254.79, 2019.0, 1.0, 1.0, 18.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[272.52, 2019.0, 1.0, 1.0, 19.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[205.06, 2019.0, 1.0, 1.0, 20.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[237.29, 2019.0, 1.0, 1.0, 21.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[286.86, 2019.0, 1.0, 1.0, 22.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[251.5, 2019.0, 1.0, 1.0, 23.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[215.51999999999998, 2019.0, 1.0, 2.0, 0.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[249.28, 2019.0, 1.0, 2.0, 1.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[249.01, 2019.0, 1.0, 2.0, 2.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[215.02, 2019.0, 1.0, 2.0, 3.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[266.24, 2019.0, 1.0, 2.0, 4.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[216.233, 2019.0, 1.0, 2.0, 5.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[232.04, 2019.0, 1.0, 2.0, 6.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[266.99, 2019.0, 1.0, 2.0, 7.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[253.26999999999998, 2019.0, 1.0, 2.0, 8.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[256.28, 2019.0, 1.0, 2.0, 9.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[253.22, 2019.0, 1.0, 2.0, 10.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[218.47, 2019.0, 1.0, 2.0, 11.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[221.73000000000002, 2019.0, 1.0, 2.0, 12.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[235.01, 2019.0, 1.0, 2.0, 13.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[165.49, 2019.0, 1.0, 2.0, 14.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[214.03, 2019.0, 1.0, 2.0, 15.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[184.01, 2019.0, 1.0, 2.0, 16.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 0.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[201.76999999999998, 2019.0, 1.0, 2.0, 17.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[220.8, 2019.0, 1.0, 2.0, 18.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[209.27, 2019.0, 1.0, 2.0, 19.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[276.01, 2019.0, 1.0, 2.0, 20.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[258.18, 2019.0, 1.0, 2.0, 21.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[223.53, 2019.0, 1.0, 2.0, 22.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[272.29, 2019.0, 1.0, 2.0, 23.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[252.24, 2019.0, 1.0, 3.0, 0.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[235.23000000000002, 2019.0, 1.0, 3.0, 1.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[285.29, 2019.0, 1.0, 3.0, 2.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[253.01, 2019.0, 1.0, 3.0, 3.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[252.78, 2019.0, 1.0, 3.0, 4.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 0.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[302.51, 2019.0, 1.0, 3.0, 5.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[268.233, 2019.0, 1.0, 3.0, 6.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[270.48, 2019.0, 1.0, 3.0, 7.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[308.83, 2019.0, 1.0, 3.0, 8.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[298.24, 2019.0, 1.0, 3.0, 9.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[501.47, 2019.0, 1.0, 3.0, 10.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[719.95, 2019.0, 1.0, 3.0, 11.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[854.0, 2019.0, 1.0, 3.0, 12.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[857.0, 2019.0, 1.0, 3.0, 13.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[733.9, 2019.0, 1.0, 3.0, 14.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[762.0, 2019.0, 1.0, 3.0, 15.0] => [0, 1, 1, 1, 1, 1] (expected [1.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[717.8, 2019.0, 1.0, 3.0, 16.0] => [0, 1, 1, 1, 1, 1] (expected [1.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[655.29, 2019.0, 1.0, 3.0, 17.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[658.96, 2019.0, 1.0, 3.0, 18.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[662.0, 2019.0, 1.0, 3.0, 19.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[656.51, 2019.0, 1.0, 3.0, 20.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[615.79, 2019.0, 1.0, 3.0, 21.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[327.81, 2019.0, 1.0, 3.0, 22.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[359.75, 2019.0, 1.0, 3.0, 23.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[424.08, 2019.0, 1.0, 4.0, 0.0] => [0, 1, 1, 1, 1, 1] (expected [1.0, 1.0, 0.0, 0.0, 1.0, 1.0])\n",
            "[450.9, 2019.0, 1.0, 4.0, 1.0] => [0, 1, 1, 1, 1, 1] (expected [1.0, 1.0, 0.0, 0.0, 1.0, 1.0])\n",
            "[389.3, 2019.0, 1.0, 4.0, 2.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 1.0, 1.0])\n",
            "[389.775, 2019.0, 1.0, 4.0, 3.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 1.0, 1.0])\n",
            "[424.73, 2019.0, 1.0, 4.0, 4.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 1.0, 1.0])\n",
            "[614.08, 2019.0, 1.0, 4.0, 5.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[595.53, 2019.0, 1.0, 4.0, 6.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 1.0, 1.0])\n",
            "[681.28, 2019.0, 1.0, 4.0, 7.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 1.0, 1.0])\n",
            "[568.74, 2019.0, 1.0, 4.0, 8.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[768.0, 2019.0, 1.0, 4.0, 9.0] => [0, 1, 1, 1, 1, 1] (expected [1.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[703.96, 2019.0, 1.0, 4.0, 10.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[872.23, 2019.0, 1.0, 4.0, 11.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[902.6800000000001, 2019.0, 1.0, 4.0, 12.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[806.5, 2019.0, 1.0, 4.0, 13.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[736.8, 2019.0, 1.0, 4.0, 14.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[616.0, 2019.0, 1.0, 4.0, 15.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[408.19, 2019.0, 1.0, 4.0, 16.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[588.4, 2019.0, 1.0, 4.0, 17.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[581.76, 2019.0, 1.0, 4.0, 18.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[405.5, 2019.0, 1.0, 4.0, 19.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[500.24, 2019.0, 1.0, 4.0, 20.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[392.025, 2019.0, 1.0, 4.0, 21.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[186.23, 2019.0, 1.0, 4.0, 22.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[151.04, 2019.0, 1.0, 4.0, 23.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[231.96, 2019.0, 1.0, 5.0, 0.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[184.07, 2019.0, 1.0, 5.0, 1.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[237.19, 2019.0, 1.0, 5.0, 2.0] => [0, 1, 1, 1, 1, 1] (expected [1.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[330.23799999999994, 2019.0, 1.0, 5.0, 3.0] => [0, 1, 1, 1, 1, 1] (expected [1.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['Ventilation', 'Soket Plugs', 'Lighting', 'Other Electricity', 'Cooling', 'Heating']\n",
        "print(classification_report(y_test1, predictions, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xGcJOxauHbJ",
        "outputId": "626f8efb-a04d-4323-a1ab-3eed61ac03ac"
      },
      "id": "8xGcJOxauHbJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "      Ventilation       0.00      0.00      0.00      3912\n",
            "      Soket Plugs       0.93      1.00      0.96      8164\n",
            "         Lighting       0.61      1.00      0.76      5362\n",
            "Other Electricity       0.64      1.00      0.78      5572\n",
            "          Cooling       0.72      1.00      0.84      6324\n",
            "          Heating       0.57      1.00      0.73      5012\n",
            "\n",
            "        micro avg       0.69      0.89      0.78     34346\n",
            "        macro avg       0.58      0.83      0.68     34346\n",
            "     weighted avg       0.64      0.89      0.73     34346\n",
            "      samples avg       0.69      0.90      0.77     34346\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=5, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(6, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c3L_FDZA_k_",
        "outputId": "14965da9-d0c3-495f-d0dd-ac2d4bcb67c1"
      },
      "id": "-c3L_FDZA_k_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_13 (Dense)            (None, 12)                72        \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 100)               1300      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 6)                 606       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,978\n",
            "Trainable params: 1,978\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train1, y_train1, epochs=500, batch_size=32,validation_split=0.15,validation_data=None,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTjCDXkSBA_V",
        "outputId": "705289f7-aef7-4ec5-d805-d7b087809162"
      },
      "id": "aTjCDXkSBA_V",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "464/464 [==============================] - 3s 5ms/step - loss: 1.9393 - accuracy: 0.1988 - val_loss: 1.4932 - val_accuracy: 0.0962\n",
            "Epoch 2/500\n",
            "464/464 [==============================] - 2s 5ms/step - loss: 0.5193 - accuracy: 0.2367 - val_loss: 1.0475 - val_accuracy: 0.2528\n",
            "Epoch 3/500\n",
            "464/464 [==============================] - 2s 5ms/step - loss: 0.5120 - accuracy: 0.2133 - val_loss: 0.9661 - val_accuracy: 0.5548\n",
            "Epoch 4/500\n",
            "464/464 [==============================] - 2s 5ms/step - loss: 0.4954 - accuracy: 0.2187 - val_loss: 0.8291 - val_accuracy: 0.4952\n",
            "Epoch 5/500\n",
            "464/464 [==============================] - 2s 5ms/step - loss: 0.5026 - accuracy: 0.2177 - val_loss: 1.0818 - val_accuracy: 0.1222\n",
            "Epoch 6/500\n",
            "464/464 [==============================] - 3s 6ms/step - loss: 0.4782 - accuracy: 0.2474 - val_loss: 0.7076 - val_accuracy: 0.6812\n",
            "Epoch 7/500\n",
            "464/464 [==============================] - 2s 4ms/step - loss: 0.4673 - accuracy: 0.2140 - val_loss: 1.5443 - val_accuracy: 0.0019\n",
            "Epoch 8/500\n",
            "464/464 [==============================] - 3s 6ms/step - loss: 0.4540 - accuracy: 0.2037 - val_loss: 1.0707 - val_accuracy: 0.1031\n",
            "Epoch 9/500\n",
            "464/464 [==============================] - 2s 5ms/step - loss: 0.4482 - accuracy: 0.1917 - val_loss: 0.9659 - val_accuracy: 0.6907\n",
            "Epoch 10/500\n",
            "464/464 [==============================] - 2s 5ms/step - loss: 0.4344 - accuracy: 0.2206 - val_loss: 1.1500 - val_accuracy: 0.1042\n",
            "Epoch 11/500\n",
            "464/464 [==============================] - 3s 6ms/step - loss: 0.4341 - accuracy: 0.2091 - val_loss: 0.8637 - val_accuracy: 0.3566\n",
            "Epoch 12/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.4276 - accuracy: 0.1991 - val_loss: 0.9289 - val_accuracy: 0.1019\n",
            "Epoch 13/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.4130 - accuracy: 0.1751 - val_loss: 1.0581 - val_accuracy: 0.0409\n",
            "Epoch 14/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.4148 - accuracy: 0.1981 - val_loss: 0.8948 - val_accuracy: 0.4513\n",
            "Epoch 15/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.4123 - accuracy: 0.1980 - val_loss: 1.0769 - val_accuracy: 0.6537\n",
            "Epoch 16/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.3974 - accuracy: 0.1766 - val_loss: 1.0076 - val_accuracy: 0.4983\n",
            "Epoch 17/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.3965 - accuracy: 0.1858 - val_loss: 1.1942 - val_accuracy: 0.1126\n",
            "Epoch 18/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.3886 - accuracy: 0.1577 - val_loss: 0.9592 - val_accuracy: 0.2810\n",
            "Epoch 19/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.3882 - accuracy: 0.1681 - val_loss: 0.9434 - val_accuracy: 0.2635\n",
            "Epoch 20/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.3839 - accuracy: 0.1743 - val_loss: 0.9103 - val_accuracy: 0.1352\n",
            "Epoch 21/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.3801 - accuracy: 0.1712 - val_loss: 1.0542 - val_accuracy: 0.1180\n",
            "Epoch 22/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.3751 - accuracy: 0.1722 - val_loss: 0.9957 - val_accuracy: 0.1439\n",
            "Epoch 23/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.3699 - accuracy: 0.1512 - val_loss: 0.9825 - val_accuracy: 0.1516\n",
            "Epoch 24/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.3656 - accuracy: 0.1451 - val_loss: 1.0134 - val_accuracy: 0.1466\n",
            "Epoch 25/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.3598 - accuracy: 0.1387 - val_loss: 1.0285 - val_accuracy: 0.1432\n",
            "Epoch 26/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.1283 - val_loss: 1.1020 - val_accuracy: 0.0970\n",
            "Epoch 27/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.3034 - accuracy: 0.1184 - val_loss: 1.1375 - val_accuracy: 0.0771\n",
            "Epoch 28/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2918 - accuracy: 0.1183 - val_loss: 1.0621 - val_accuracy: 0.1119\n",
            "Epoch 29/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2871 - accuracy: 0.1033 - val_loss: 1.0656 - val_accuracy: 0.1585\n",
            "Epoch 30/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2843 - accuracy: 0.1057 - val_loss: 1.1616 - val_accuracy: 0.1081\n",
            "Epoch 31/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2835 - accuracy: 0.1059 - val_loss: 1.1973 - val_accuracy: 0.0439\n",
            "Epoch 32/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2830 - accuracy: 0.1035 - val_loss: 0.9803 - val_accuracy: 0.3085\n",
            "Epoch 33/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2792 - accuracy: 0.0999 - val_loss: 1.1204 - val_accuracy: 0.0622\n",
            "Epoch 34/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2805 - accuracy: 0.1043 - val_loss: 1.2441 - val_accuracy: 0.1466\n",
            "Epoch 35/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2794 - accuracy: 0.1007 - val_loss: 1.2422 - val_accuracy: 0.0523\n",
            "Epoch 36/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2767 - accuracy: 0.0946 - val_loss: 1.2495 - val_accuracy: 0.0118\n",
            "Epoch 37/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2792 - accuracy: 0.1022 - val_loss: 1.1170 - val_accuracy: 0.0294\n",
            "Epoch 38/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2759 - accuracy: 0.0935 - val_loss: 1.0128 - val_accuracy: 0.2784\n",
            "Epoch 39/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2742 - accuracy: 0.1100 - val_loss: 1.0639 - val_accuracy: 0.1695\n",
            "Epoch 40/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2748 - accuracy: 0.1007 - val_loss: 1.2679 - val_accuracy: 0.0279\n",
            "Epoch 41/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2734 - accuracy: 0.0989 - val_loss: 1.1865 - val_accuracy: 0.1585\n",
            "Epoch 42/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2724 - accuracy: 0.0989 - val_loss: 1.1459 - val_accuracy: 0.0649\n",
            "Epoch 43/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2721 - accuracy: 0.0990 - val_loss: 1.1541 - val_accuracy: 0.0325\n",
            "Epoch 44/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2708 - accuracy: 0.1042 - val_loss: 1.1601 - val_accuracy: 0.0332\n",
            "Epoch 45/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2703 - accuracy: 0.0990 - val_loss: 1.1581 - val_accuracy: 0.0699\n",
            "Epoch 46/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2694 - accuracy: 0.1061 - val_loss: 1.2373 - val_accuracy: 0.0283\n",
            "Epoch 47/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2695 - accuracy: 0.1082 - val_loss: 1.1379 - val_accuracy: 0.1058\n",
            "Epoch 48/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2675 - accuracy: 0.1088 - val_loss: 1.2327 - val_accuracy: 0.0191\n",
            "Epoch 49/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2677 - accuracy: 0.1126 - val_loss: 1.3204 - val_accuracy: 0.0137\n",
            "Epoch 50/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2657 - accuracy: 0.1152 - val_loss: 1.1693 - val_accuracy: 0.0542\n",
            "Epoch 51/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2677 - accuracy: 0.1175 - val_loss: 1.1717 - val_accuracy: 0.0172\n",
            "Epoch 52/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2662 - accuracy: 0.1162 - val_loss: 1.0343 - val_accuracy: 0.0947\n",
            "Epoch 53/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2614 - accuracy: 0.1164 - val_loss: 1.1836 - val_accuracy: 0.0233\n",
            "Epoch 54/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2634 - accuracy: 0.1212 - val_loss: 1.1299 - val_accuracy: 0.1611\n",
            "Epoch 55/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2637 - accuracy: 0.1235 - val_loss: 1.1249 - val_accuracy: 0.2310\n",
            "Epoch 56/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2616 - accuracy: 0.1305 - val_loss: 1.0182 - val_accuracy: 0.2062\n",
            "Epoch 57/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2620 - accuracy: 0.1290 - val_loss: 1.2921 - val_accuracy: 0.1233\n",
            "Epoch 58/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2633 - accuracy: 0.1346 - val_loss: 1.0411 - val_accuracy: 0.2696\n",
            "Epoch 59/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2605 - accuracy: 0.1342 - val_loss: 1.1665 - val_accuracy: 0.1615\n",
            "Epoch 60/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2593 - accuracy: 0.1274 - val_loss: 1.1634 - val_accuracy: 0.1722\n",
            "Epoch 61/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2599 - accuracy: 0.1213 - val_loss: 1.4651 - val_accuracy: 0.1027\n",
            "Epoch 62/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2605 - accuracy: 0.1318 - val_loss: 1.2466 - val_accuracy: 0.1890\n",
            "Epoch 63/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2587 - accuracy: 0.1342 - val_loss: 1.2124 - val_accuracy: 0.1100\n",
            "Epoch 64/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2588 - accuracy: 0.1303 - val_loss: 1.2895 - val_accuracy: 0.1581\n",
            "Epoch 65/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2603 - accuracy: 0.1321 - val_loss: 1.1621 - val_accuracy: 0.1936\n",
            "Epoch 66/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2583 - accuracy: 0.1329 - val_loss: 1.2399 - val_accuracy: 0.2027\n",
            "Epoch 67/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2613 - accuracy: 0.1330 - val_loss: 1.2236 - val_accuracy: 0.2161\n",
            "Epoch 68/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2591 - accuracy: 0.1372 - val_loss: 1.2366 - val_accuracy: 0.4200\n",
            "Epoch 69/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2612 - accuracy: 0.1333 - val_loss: 1.0647 - val_accuracy: 0.3807\n",
            "Epoch 70/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2569 - accuracy: 0.1270 - val_loss: 1.3099 - val_accuracy: 0.3375\n",
            "Epoch 71/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2596 - accuracy: 0.1330 - val_loss: 1.4104 - val_accuracy: 0.1256\n",
            "Epoch 72/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2571 - accuracy: 0.1327 - val_loss: 1.2287 - val_accuracy: 0.2959\n",
            "Epoch 73/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2553 - accuracy: 0.1265 - val_loss: 1.2504 - val_accuracy: 0.3723\n",
            "Epoch 74/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2569 - accuracy: 0.1296 - val_loss: 1.1966 - val_accuracy: 0.2237\n",
            "Epoch 75/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2585 - accuracy: 0.1321 - val_loss: 1.3694 - val_accuracy: 0.2868\n",
            "Epoch 76/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2570 - accuracy: 0.1299 - val_loss: 1.4147 - val_accuracy: 0.1493\n",
            "Epoch 77/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2583 - accuracy: 0.1237 - val_loss: 1.3043 - val_accuracy: 0.2959\n",
            "Epoch 78/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2583 - accuracy: 0.1262 - val_loss: 1.4467 - val_accuracy: 0.2310\n",
            "Epoch 79/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2551 - accuracy: 0.1257 - val_loss: 1.3230 - val_accuracy: 0.3234\n",
            "Epoch 80/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2560 - accuracy: 0.1280 - val_loss: 1.4659 - val_accuracy: 0.3440\n",
            "Epoch 81/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2571 - accuracy: 0.1301 - val_loss: 1.3649 - val_accuracy: 0.2027\n",
            "Epoch 82/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2574 - accuracy: 0.1325 - val_loss: 1.2188 - val_accuracy: 0.3448\n",
            "Epoch 83/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2543 - accuracy: 0.1220 - val_loss: 1.4158 - val_accuracy: 0.3291\n",
            "Epoch 84/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2561 - accuracy: 0.1268 - val_loss: 1.2889 - val_accuracy: 0.3536\n",
            "Epoch 85/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2532 - accuracy: 0.1339 - val_loss: 1.3617 - val_accuracy: 0.3635\n",
            "Epoch 86/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2557 - accuracy: 0.1348 - val_loss: 1.3987 - val_accuracy: 0.2428\n",
            "Epoch 87/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2537 - accuracy: 0.1286 - val_loss: 1.4602 - val_accuracy: 0.2054\n",
            "Epoch 88/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2556 - accuracy: 0.1284 - val_loss: 1.3583 - val_accuracy: 0.2593\n",
            "Epoch 89/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2529 - accuracy: 0.1309 - val_loss: 1.2947 - val_accuracy: 0.3734\n",
            "Epoch 90/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2547 - accuracy: 0.1286 - val_loss: 1.3364 - val_accuracy: 0.3795\n",
            "Epoch 91/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2547 - accuracy: 0.1343 - val_loss: 1.4499 - val_accuracy: 0.3215\n",
            "Epoch 92/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2533 - accuracy: 0.1273 - val_loss: 1.3264 - val_accuracy: 0.3612\n",
            "Epoch 93/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2553 - accuracy: 0.1292 - val_loss: 1.1870 - val_accuracy: 0.4185\n",
            "Epoch 94/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2521 - accuracy: 0.1330 - val_loss: 1.3600 - val_accuracy: 0.3108\n",
            "Epoch 95/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2545 - accuracy: 0.1232 - val_loss: 1.3608 - val_accuracy: 0.4013\n",
            "Epoch 96/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2526 - accuracy: 0.1253 - val_loss: 1.5315 - val_accuracy: 0.2073\n",
            "Epoch 97/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2539 - accuracy: 0.1321 - val_loss: 1.4116 - val_accuracy: 0.4204\n",
            "Epoch 98/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2542 - accuracy: 0.1210 - val_loss: 1.4168 - val_accuracy: 0.3162\n",
            "Epoch 99/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2515 - accuracy: 0.1302 - val_loss: 1.5807 - val_accuracy: 0.2268\n",
            "Epoch 100/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2549 - accuracy: 0.1253 - val_loss: 1.5501 - val_accuracy: 0.2394\n",
            "Epoch 101/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2516 - accuracy: 0.1307 - val_loss: 1.4842 - val_accuracy: 0.4105\n",
            "Epoch 102/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2541 - accuracy: 0.1251 - val_loss: 1.5467 - val_accuracy: 0.2566\n",
            "Epoch 103/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2531 - accuracy: 0.1281 - val_loss: 1.6117 - val_accuracy: 0.2463\n",
            "Epoch 104/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2504 - accuracy: 0.1283 - val_loss: 1.4056 - val_accuracy: 0.3425\n",
            "Epoch 105/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2525 - accuracy: 0.1280 - val_loss: 1.4178 - val_accuracy: 0.4189\n",
            "Epoch 106/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2504 - accuracy: 0.1262 - val_loss: 1.2906 - val_accuracy: 0.4158\n",
            "Epoch 107/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2516 - accuracy: 0.1335 - val_loss: 1.5664 - val_accuracy: 0.3574\n",
            "Epoch 108/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2520 - accuracy: 0.1319 - val_loss: 1.4994 - val_accuracy: 0.3368\n",
            "Epoch 109/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2526 - accuracy: 0.1352 - val_loss: 1.3529 - val_accuracy: 0.4028\n",
            "Epoch 110/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2525 - accuracy: 0.1287 - val_loss: 1.5809 - val_accuracy: 0.3597\n",
            "Epoch 111/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2540 - accuracy: 0.1272 - val_loss: 1.3270 - val_accuracy: 0.3440\n",
            "Epoch 112/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2524 - accuracy: 0.1352 - val_loss: 1.4515 - val_accuracy: 0.3742\n",
            "Epoch 113/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2494 - accuracy: 0.1322 - val_loss: 1.7666 - val_accuracy: 0.3650\n",
            "Epoch 114/500\n",
            "464/464 [==============================] - 2s 3ms/step - loss: 0.2509 - accuracy: 0.1271 - val_loss: 1.4479 - val_accuracy: 0.3887\n",
            "Epoch 115/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2522 - accuracy: 0.1284 - val_loss: 1.4271 - val_accuracy: 0.5032\n",
            "Epoch 116/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2508 - accuracy: 0.1287 - val_loss: 1.4730 - val_accuracy: 0.3383\n",
            "Epoch 117/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.1268 - val_loss: 1.7116 - val_accuracy: 0.3540\n",
            "Epoch 118/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2496 - accuracy: 0.1350 - val_loss: 1.4493 - val_accuracy: 0.4952\n",
            "Epoch 119/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2494 - accuracy: 0.1322 - val_loss: 1.6944 - val_accuracy: 0.4196\n",
            "Epoch 120/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2531 - accuracy: 0.1295 - val_loss: 1.5411 - val_accuracy: 0.3200\n",
            "Epoch 121/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2497 - accuracy: 0.1280 - val_loss: 1.6071 - val_accuracy: 0.4215\n",
            "Epoch 122/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.1286 - val_loss: 1.4683 - val_accuracy: 0.3142\n",
            "Epoch 123/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2519 - accuracy: 0.1228 - val_loss: 1.6870 - val_accuracy: 0.4147\n",
            "Epoch 124/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2523 - accuracy: 0.1309 - val_loss: 1.6297 - val_accuracy: 0.3635\n",
            "Epoch 125/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2503 - accuracy: 0.1226 - val_loss: 1.5513 - val_accuracy: 0.3772\n",
            "Epoch 126/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2491 - accuracy: 0.1296 - val_loss: 1.5253 - val_accuracy: 0.3795\n",
            "Epoch 127/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2493 - accuracy: 0.1267 - val_loss: 1.4315 - val_accuracy: 0.4765\n",
            "Epoch 128/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2513 - accuracy: 0.1290 - val_loss: 1.2982 - val_accuracy: 0.4097\n",
            "Epoch 129/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2509 - accuracy: 0.1299 - val_loss: 1.6408 - val_accuracy: 0.3398\n",
            "Epoch 130/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2487 - accuracy: 0.1299 - val_loss: 1.4315 - val_accuracy: 0.3100\n",
            "Epoch 131/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2490 - accuracy: 0.1255 - val_loss: 1.8009 - val_accuracy: 0.2272\n",
            "Epoch 132/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2502 - accuracy: 0.1344 - val_loss: 1.7204 - val_accuracy: 0.3169\n",
            "Epoch 133/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2502 - accuracy: 0.1282 - val_loss: 1.5770 - val_accuracy: 0.2887\n",
            "Epoch 134/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2514 - accuracy: 0.1304 - val_loss: 1.5828 - val_accuracy: 0.4265\n",
            "Epoch 135/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2508 - accuracy: 0.1333 - val_loss: 1.4760 - val_accuracy: 0.2986\n",
            "Epoch 136/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2490 - accuracy: 0.1280 - val_loss: 1.5366 - val_accuracy: 0.3582\n",
            "Epoch 137/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2481 - accuracy: 0.1305 - val_loss: 1.6296 - val_accuracy: 0.3360\n",
            "Epoch 138/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2501 - accuracy: 0.1240 - val_loss: 1.7710 - val_accuracy: 0.3257\n",
            "Epoch 139/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2515 - accuracy: 0.1319 - val_loss: 1.4613 - val_accuracy: 0.3326\n",
            "Epoch 140/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2465 - accuracy: 0.1272 - val_loss: 1.8192 - val_accuracy: 0.3681\n",
            "Epoch 141/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2478 - accuracy: 0.1288 - val_loss: 1.7784 - val_accuracy: 0.3055\n",
            "Epoch 142/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2498 - accuracy: 0.1358 - val_loss: 1.6199 - val_accuracy: 0.5124\n",
            "Epoch 143/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2477 - accuracy: 0.1291 - val_loss: 1.4757 - val_accuracy: 0.3501\n",
            "Epoch 144/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2497 - accuracy: 0.1305 - val_loss: 1.4030 - val_accuracy: 0.5120\n",
            "Epoch 145/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2482 - accuracy: 0.1273 - val_loss: 1.5063 - val_accuracy: 0.4070\n",
            "Epoch 146/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2489 - accuracy: 0.1277 - val_loss: 1.3759 - val_accuracy: 0.3635\n",
            "Epoch 147/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2474 - accuracy: 0.1354 - val_loss: 1.5515 - val_accuracy: 0.3635\n",
            "Epoch 148/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2494 - accuracy: 0.1278 - val_loss: 1.7020 - val_accuracy: 0.3727\n",
            "Epoch 149/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.1235 - val_loss: 1.6838 - val_accuracy: 0.3058\n",
            "Epoch 150/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2484 - accuracy: 0.1277 - val_loss: 1.6700 - val_accuracy: 0.3192\n",
            "Epoch 151/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2480 - accuracy: 0.1242 - val_loss: 1.5062 - val_accuracy: 0.3223\n",
            "Epoch 152/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2480 - accuracy: 0.1319 - val_loss: 1.6930 - val_accuracy: 0.3448\n",
            "Epoch 153/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2478 - accuracy: 0.1259 - val_loss: 1.4611 - val_accuracy: 0.5284\n",
            "Epoch 154/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2467 - accuracy: 0.1287 - val_loss: 1.5796 - val_accuracy: 0.4024\n",
            "Epoch 155/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2496 - accuracy: 0.1310 - val_loss: 1.6260 - val_accuracy: 0.3986\n",
            "Epoch 156/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2482 - accuracy: 0.1260 - val_loss: 1.5894 - val_accuracy: 0.4353\n",
            "Epoch 157/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2463 - accuracy: 0.1259 - val_loss: 1.8288 - val_accuracy: 0.3971\n",
            "Epoch 158/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2471 - accuracy: 0.1285 - val_loss: 1.7426 - val_accuracy: 0.3498\n",
            "Epoch 159/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2480 - accuracy: 0.1243 - val_loss: 1.6231 - val_accuracy: 0.3788\n",
            "Epoch 160/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2473 - accuracy: 0.1294 - val_loss: 1.4736 - val_accuracy: 0.4486\n",
            "Epoch 161/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2484 - accuracy: 0.1245 - val_loss: 2.0387 - val_accuracy: 0.3708\n",
            "Epoch 162/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2469 - accuracy: 0.1263 - val_loss: 1.4161 - val_accuracy: 0.4674\n",
            "Epoch 163/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2471 - accuracy: 0.1272 - val_loss: 1.9418 - val_accuracy: 0.3982\n",
            "Epoch 164/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2459 - accuracy: 0.1307 - val_loss: 1.4903 - val_accuracy: 0.4853\n",
            "Epoch 165/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2471 - accuracy: 0.1315 - val_loss: 1.6612 - val_accuracy: 0.3631\n",
            "Epoch 166/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2469 - accuracy: 0.1306 - val_loss: 1.3732 - val_accuracy: 0.4998\n",
            "Epoch 167/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2488 - accuracy: 0.1313 - val_loss: 1.5733 - val_accuracy: 0.4101\n",
            "Epoch 168/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2477 - accuracy: 0.1274 - val_loss: 1.6245 - val_accuracy: 0.4819\n",
            "Epoch 169/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2446 - accuracy: 0.1318 - val_loss: 1.7221 - val_accuracy: 0.4605\n",
            "Epoch 170/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2472 - accuracy: 0.1264 - val_loss: 1.5314 - val_accuracy: 0.4567\n",
            "Epoch 171/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2453 - accuracy: 0.1297 - val_loss: 1.4857 - val_accuracy: 0.4822\n",
            "Epoch 172/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2461 - accuracy: 0.1274 - val_loss: 1.7009 - val_accuracy: 0.3761\n",
            "Epoch 173/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2465 - accuracy: 0.1265 - val_loss: 1.8380 - val_accuracy: 0.3761\n",
            "Epoch 174/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2480 - accuracy: 0.1230 - val_loss: 1.5862 - val_accuracy: 0.3066\n",
            "Epoch 175/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2470 - accuracy: 0.1286 - val_loss: 1.8788 - val_accuracy: 0.4486\n",
            "Epoch 176/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2468 - accuracy: 0.1280 - val_loss: 1.7820 - val_accuracy: 0.3322\n",
            "Epoch 177/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2494 - accuracy: 0.1312 - val_loss: 2.0928 - val_accuracy: 0.3162\n",
            "Epoch 178/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.1309 - val_loss: 1.7343 - val_accuracy: 0.4712\n",
            "Epoch 179/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.1312 - val_loss: 1.6491 - val_accuracy: 0.4429\n",
            "Epoch 180/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2445 - accuracy: 0.1305 - val_loss: 1.7610 - val_accuracy: 0.4120\n",
            "Epoch 181/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2465 - accuracy: 0.1275 - val_loss: 1.8600 - val_accuracy: 0.3669\n",
            "Epoch 182/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2452 - accuracy: 0.1338 - val_loss: 1.8649 - val_accuracy: 0.3158\n",
            "Epoch 183/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2451 - accuracy: 0.1297 - val_loss: 1.6464 - val_accuracy: 0.3700\n",
            "Epoch 184/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2469 - accuracy: 0.1353 - val_loss: 1.7069 - val_accuracy: 0.4983\n",
            "Epoch 185/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2464 - accuracy: 0.1268 - val_loss: 1.9726 - val_accuracy: 0.4570\n",
            "Epoch 186/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2447 - accuracy: 0.1331 - val_loss: 1.7883 - val_accuracy: 0.4399\n",
            "Epoch 187/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2467 - accuracy: 0.1281 - val_loss: 1.6203 - val_accuracy: 0.4391\n",
            "Epoch 188/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2451 - accuracy: 0.1307 - val_loss: 1.4734 - val_accuracy: 0.5200\n",
            "Epoch 189/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2481 - accuracy: 0.1363 - val_loss: 2.2071 - val_accuracy: 0.3887\n",
            "Epoch 190/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2453 - accuracy: 0.1321 - val_loss: 1.7756 - val_accuracy: 0.4544\n",
            "Epoch 191/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2461 - accuracy: 0.1332 - val_loss: 1.8495 - val_accuracy: 0.3757\n",
            "Epoch 192/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2456 - accuracy: 0.1288 - val_loss: 1.6764 - val_accuracy: 0.4807\n",
            "Epoch 193/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2459 - accuracy: 0.1323 - val_loss: 1.9000 - val_accuracy: 0.4364\n",
            "Epoch 194/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2448 - accuracy: 0.1315 - val_loss: 1.5786 - val_accuracy: 0.4777\n",
            "Epoch 195/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2439 - accuracy: 0.1361 - val_loss: 1.8058 - val_accuracy: 0.4173\n",
            "Epoch 196/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2469 - accuracy: 0.1274 - val_loss: 2.1092 - val_accuracy: 0.3013\n",
            "Epoch 197/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2443 - accuracy: 0.1375 - val_loss: 1.5272 - val_accuracy: 0.4887\n",
            "Epoch 198/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2464 - accuracy: 0.1281 - val_loss: 1.6731 - val_accuracy: 0.4536\n",
            "Epoch 199/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2448 - accuracy: 0.1307 - val_loss: 2.2015 - val_accuracy: 0.3165\n",
            "Epoch 200/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2443 - accuracy: 0.1346 - val_loss: 1.5681 - val_accuracy: 0.5250\n",
            "Epoch 201/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2448 - accuracy: 0.1321 - val_loss: 1.9665 - val_accuracy: 0.4903\n",
            "Epoch 202/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2460 - accuracy: 0.1286 - val_loss: 1.5973 - val_accuracy: 0.3952\n",
            "Epoch 203/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2451 - accuracy: 0.1299 - val_loss: 1.6002 - val_accuracy: 0.4498\n",
            "Epoch 204/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2456 - accuracy: 0.1337 - val_loss: 2.0576 - val_accuracy: 0.4322\n",
            "Epoch 205/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2449 - accuracy: 0.1318 - val_loss: 1.4635 - val_accuracy: 0.5491\n",
            "Epoch 206/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2449 - accuracy: 0.1358 - val_loss: 1.8917 - val_accuracy: 0.4887\n",
            "Epoch 207/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2453 - accuracy: 0.1346 - val_loss: 1.8043 - val_accuracy: 0.4483\n",
            "Epoch 208/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2451 - accuracy: 0.1361 - val_loss: 1.6184 - val_accuracy: 0.4261\n",
            "Epoch 209/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2444 - accuracy: 0.1325 - val_loss: 1.9348 - val_accuracy: 0.4544\n",
            "Epoch 210/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2442 - accuracy: 0.1366 - val_loss: 1.8983 - val_accuracy: 0.3654\n",
            "Epoch 211/500\n",
            "464/464 [==============================] - 2s 4ms/step - loss: 0.2443 - accuracy: 0.1282 - val_loss: 1.9376 - val_accuracy: 0.4276\n",
            "Epoch 212/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2431 - accuracy: 0.1344 - val_loss: 1.8609 - val_accuracy: 0.4666\n",
            "Epoch 213/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2448 - accuracy: 0.1330 - val_loss: 2.1126 - val_accuracy: 0.4536\n",
            "Epoch 214/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2445 - accuracy: 0.1308 - val_loss: 1.9300 - val_accuracy: 0.4299\n",
            "Epoch 215/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2437 - accuracy: 0.1365 - val_loss: 1.7868 - val_accuracy: 0.5071\n",
            "Epoch 216/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2442 - accuracy: 0.1313 - val_loss: 1.7220 - val_accuracy: 0.4315\n",
            "Epoch 217/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2435 - accuracy: 0.1298 - val_loss: 2.0168 - val_accuracy: 0.5021\n",
            "Epoch 218/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2453 - accuracy: 0.1355 - val_loss: 1.6002 - val_accuracy: 0.4708\n",
            "Epoch 219/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2438 - accuracy: 0.1298 - val_loss: 2.0973 - val_accuracy: 0.4666\n",
            "Epoch 220/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2438 - accuracy: 0.1330 - val_loss: 1.6174 - val_accuracy: 0.5529\n",
            "Epoch 221/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2446 - accuracy: 0.1338 - val_loss: 2.0417 - val_accuracy: 0.3780\n",
            "Epoch 222/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2459 - accuracy: 0.1290 - val_loss: 2.0259 - val_accuracy: 0.3608\n",
            "Epoch 223/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2437 - accuracy: 0.1328 - val_loss: 2.2412 - val_accuracy: 0.3310\n",
            "Epoch 224/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2443 - accuracy: 0.1266 - val_loss: 1.8153 - val_accuracy: 0.4635\n",
            "Epoch 225/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2443 - accuracy: 0.1325 - val_loss: 2.0271 - val_accuracy: 0.4544\n",
            "Epoch 226/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2437 - accuracy: 0.1254 - val_loss: 2.0263 - val_accuracy: 0.4299\n",
            "Epoch 227/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2450 - accuracy: 0.1301 - val_loss: 1.6225 - val_accuracy: 0.5391\n",
            "Epoch 228/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2423 - accuracy: 0.1293 - val_loss: 2.1060 - val_accuracy: 0.4582\n",
            "Epoch 229/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2445 - accuracy: 0.1274 - val_loss: 1.6746 - val_accuracy: 0.3551\n",
            "Epoch 230/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2448 - accuracy: 0.1272 - val_loss: 2.4790 - val_accuracy: 0.3635\n",
            "Epoch 231/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2443 - accuracy: 0.1324 - val_loss: 1.9674 - val_accuracy: 0.4036\n",
            "Epoch 232/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2431 - accuracy: 0.1296 - val_loss: 1.7034 - val_accuracy: 0.4128\n",
            "Epoch 233/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2443 - accuracy: 0.1291 - val_loss: 1.9046 - val_accuracy: 0.4429\n",
            "Epoch 234/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2436 - accuracy: 0.1303 - val_loss: 1.8483 - val_accuracy: 0.4597\n",
            "Epoch 235/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2426 - accuracy: 0.1295 - val_loss: 2.1727 - val_accuracy: 0.3937\n",
            "Epoch 236/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2427 - accuracy: 0.1270 - val_loss: 1.9110 - val_accuracy: 0.3700\n",
            "Epoch 237/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2437 - accuracy: 0.1301 - val_loss: 1.6384 - val_accuracy: 0.5724\n",
            "Epoch 238/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2445 - accuracy: 0.1307 - val_loss: 2.1664 - val_accuracy: 0.3898\n",
            "Epoch 239/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2442 - accuracy: 0.1265 - val_loss: 1.5027 - val_accuracy: 0.4265\n",
            "Epoch 240/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2428 - accuracy: 0.1348 - val_loss: 1.7204 - val_accuracy: 0.5208\n",
            "Epoch 241/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2433 - accuracy: 0.1276 - val_loss: 1.7320 - val_accuracy: 0.4769\n",
            "Epoch 242/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2439 - accuracy: 0.1283 - val_loss: 1.7930 - val_accuracy: 0.4074\n",
            "Epoch 243/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2433 - accuracy: 0.1348 - val_loss: 2.2111 - val_accuracy: 0.4815\n",
            "Epoch 244/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2441 - accuracy: 0.1333 - val_loss: 1.7327 - val_accuracy: 0.5410\n",
            "Epoch 245/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2431 - accuracy: 0.1290 - val_loss: 2.1960 - val_accuracy: 0.4494\n",
            "Epoch 246/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2424 - accuracy: 0.1310 - val_loss: 1.7891 - val_accuracy: 0.5441\n",
            "Epoch 247/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2432 - accuracy: 0.1330 - val_loss: 2.0756 - val_accuracy: 0.4021\n",
            "Epoch 248/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2453 - accuracy: 0.1284 - val_loss: 1.9188 - val_accuracy: 0.4135\n",
            "Epoch 249/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2428 - accuracy: 0.1334 - val_loss: 1.6578 - val_accuracy: 0.4555\n",
            "Epoch 250/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2435 - accuracy: 0.1313 - val_loss: 2.0604 - val_accuracy: 0.4456\n",
            "Epoch 251/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2444 - accuracy: 0.1280 - val_loss: 1.8805 - val_accuracy: 0.4574\n",
            "Epoch 252/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2442 - accuracy: 0.1259 - val_loss: 2.0889 - val_accuracy: 0.4078\n",
            "Epoch 253/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2427 - accuracy: 0.1332 - val_loss: 1.6138 - val_accuracy: 0.5384\n",
            "Epoch 254/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2440 - accuracy: 0.1383 - val_loss: 1.6563 - val_accuracy: 0.4334\n",
            "Epoch 255/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2421 - accuracy: 0.1273 - val_loss: 1.8487 - val_accuracy: 0.4437\n",
            "Epoch 256/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2439 - accuracy: 0.1331 - val_loss: 2.0061 - val_accuracy: 0.3215\n",
            "Epoch 257/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2436 - accuracy: 0.1389 - val_loss: 1.9393 - val_accuracy: 0.4456\n",
            "Epoch 258/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2426 - accuracy: 0.1288 - val_loss: 1.7186 - val_accuracy: 0.4150\n",
            "Epoch 259/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2413 - accuracy: 0.1326 - val_loss: 1.7012 - val_accuracy: 0.3669\n",
            "Epoch 260/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2430 - accuracy: 0.1304 - val_loss: 1.8742 - val_accuracy: 0.4154\n",
            "Epoch 261/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2424 - accuracy: 0.1308 - val_loss: 1.9454 - val_accuracy: 0.4364\n",
            "Epoch 262/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2423 - accuracy: 0.1278 - val_loss: 1.9727 - val_accuracy: 0.4486\n",
            "Epoch 263/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2440 - accuracy: 0.1313 - val_loss: 1.6316 - val_accuracy: 0.4414\n",
            "Epoch 264/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2421 - accuracy: 0.1284 - val_loss: 2.0885 - val_accuracy: 0.3135\n",
            "Epoch 265/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2418 - accuracy: 0.1345 - val_loss: 2.2160 - val_accuracy: 0.4154\n",
            "Epoch 266/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2439 - accuracy: 0.1346 - val_loss: 2.1461 - val_accuracy: 0.3444\n",
            "Epoch 267/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2431 - accuracy: 0.1339 - val_loss: 1.7885 - val_accuracy: 0.3929\n",
            "Epoch 268/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2429 - accuracy: 0.1309 - val_loss: 2.0145 - val_accuracy: 0.2822\n",
            "Epoch 269/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2423 - accuracy: 0.1289 - val_loss: 2.1207 - val_accuracy: 0.3398\n",
            "Epoch 270/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2421 - accuracy: 0.1391 - val_loss: 1.8067 - val_accuracy: 0.3738\n",
            "Epoch 271/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2441 - accuracy: 0.1321 - val_loss: 1.8574 - val_accuracy: 0.4124\n",
            "Epoch 272/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2427 - accuracy: 0.1275 - val_loss: 2.0908 - val_accuracy: 0.3872\n",
            "Epoch 273/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2424 - accuracy: 0.1276 - val_loss: 2.5500 - val_accuracy: 0.3456\n",
            "Epoch 274/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2411 - accuracy: 0.1339 - val_loss: 2.0826 - val_accuracy: 0.3944\n",
            "Epoch 275/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2434 - accuracy: 0.1289 - val_loss: 1.9788 - val_accuracy: 0.4483\n",
            "Epoch 276/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2422 - accuracy: 0.1319 - val_loss: 2.7505 - val_accuracy: 0.2367\n",
            "Epoch 277/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2420 - accuracy: 0.1311 - val_loss: 1.9235 - val_accuracy: 0.3402\n",
            "Epoch 278/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2412 - accuracy: 0.1277 - val_loss: 2.1385 - val_accuracy: 0.5269\n",
            "Epoch 279/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2423 - accuracy: 0.1336 - val_loss: 1.9785 - val_accuracy: 0.4570\n",
            "Epoch 280/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2427 - accuracy: 0.1301 - val_loss: 2.1943 - val_accuracy: 0.3169\n",
            "Epoch 281/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2419 - accuracy: 0.1310 - val_loss: 2.3813 - val_accuracy: 0.3032\n",
            "Epoch 282/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2440 - accuracy: 0.1330 - val_loss: 2.2038 - val_accuracy: 0.3864\n",
            "Epoch 283/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2412 - accuracy: 0.1303 - val_loss: 2.1023 - val_accuracy: 0.3624\n",
            "Epoch 284/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2419 - accuracy: 0.1287 - val_loss: 2.1772 - val_accuracy: 0.4047\n",
            "Epoch 285/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2431 - accuracy: 0.1376 - val_loss: 2.1713 - val_accuracy: 0.3673\n",
            "Epoch 286/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2440 - accuracy: 0.1351 - val_loss: 1.9341 - val_accuracy: 0.3543\n",
            "Epoch 287/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2427 - accuracy: 0.1337 - val_loss: 1.7063 - val_accuracy: 0.5193\n",
            "Epoch 288/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2415 - accuracy: 0.1346 - val_loss: 2.0364 - val_accuracy: 0.3967\n",
            "Epoch 289/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2430 - accuracy: 0.1342 - val_loss: 2.1208 - val_accuracy: 0.4185\n",
            "Epoch 290/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2440 - accuracy: 0.1296 - val_loss: 2.0450 - val_accuracy: 0.4059\n",
            "Epoch 291/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2419 - accuracy: 0.1299 - val_loss: 2.2191 - val_accuracy: 0.3414\n",
            "Epoch 292/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2417 - accuracy: 0.1317 - val_loss: 1.6198 - val_accuracy: 0.5662\n",
            "Epoch 293/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2416 - accuracy: 0.1288 - val_loss: 1.9762 - val_accuracy: 0.4929\n",
            "Epoch 294/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2426 - accuracy: 0.1357 - val_loss: 1.9703 - val_accuracy: 0.4204\n",
            "Epoch 295/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2421 - accuracy: 0.1319 - val_loss: 2.2287 - val_accuracy: 0.3803\n",
            "Epoch 296/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2434 - accuracy: 0.1293 - val_loss: 1.8281 - val_accuracy: 0.4120\n",
            "Epoch 297/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2409 - accuracy: 0.1295 - val_loss: 1.9627 - val_accuracy: 0.4326\n",
            "Epoch 298/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2415 - accuracy: 0.1344 - val_loss: 1.8910 - val_accuracy: 0.4868\n",
            "Epoch 299/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2426 - accuracy: 0.1334 - val_loss: 1.9116 - val_accuracy: 0.4742\n",
            "Epoch 300/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2440 - accuracy: 0.1316 - val_loss: 2.4020 - val_accuracy: 0.3952\n",
            "Epoch 301/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2414 - accuracy: 0.1307 - val_loss: 2.1468 - val_accuracy: 0.3990\n",
            "Epoch 302/500\n",
            "464/464 [==============================] - 2s 3ms/step - loss: 0.2410 - accuracy: 0.1309 - val_loss: 2.0259 - val_accuracy: 0.3925\n",
            "Epoch 303/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2422 - accuracy: 0.1301 - val_loss: 2.0161 - val_accuracy: 0.3280\n",
            "Epoch 304/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2423 - accuracy: 0.1278 - val_loss: 2.2204 - val_accuracy: 0.3757\n",
            "Epoch 305/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2414 - accuracy: 0.1278 - val_loss: 1.7221 - val_accuracy: 0.4372\n",
            "Epoch 306/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2426 - accuracy: 0.1345 - val_loss: 2.0235 - val_accuracy: 0.3528\n",
            "Epoch 307/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2407 - accuracy: 0.1264 - val_loss: 1.9942 - val_accuracy: 0.3902\n",
            "Epoch 308/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2413 - accuracy: 0.1267 - val_loss: 1.7342 - val_accuracy: 0.4647\n",
            "Epoch 309/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2415 - accuracy: 0.1302 - val_loss: 1.9475 - val_accuracy: 0.4028\n",
            "Epoch 310/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2414 - accuracy: 0.1321 - val_loss: 2.0446 - val_accuracy: 0.3364\n",
            "Epoch 311/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2418 - accuracy: 0.1267 - val_loss: 1.9243 - val_accuracy: 0.3360\n",
            "Epoch 312/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2423 - accuracy: 0.1315 - val_loss: 1.8277 - val_accuracy: 0.3803\n",
            "Epoch 313/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2427 - accuracy: 0.1265 - val_loss: 2.1370 - val_accuracy: 0.4177\n",
            "Epoch 314/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2413 - accuracy: 0.1283 - val_loss: 2.3300 - val_accuracy: 0.2505\n",
            "Epoch 315/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2411 - accuracy: 0.1292 - val_loss: 2.1376 - val_accuracy: 0.4548\n",
            "Epoch 316/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2419 - accuracy: 0.1286 - val_loss: 2.3880 - val_accuracy: 0.4082\n",
            "Epoch 317/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2409 - accuracy: 0.1341 - val_loss: 1.9270 - val_accuracy: 0.3333\n",
            "Epoch 318/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2412 - accuracy: 0.1293 - val_loss: 1.9133 - val_accuracy: 0.4326\n",
            "Epoch 319/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2418 - accuracy: 0.1280 - val_loss: 1.6621 - val_accuracy: 0.3685\n",
            "Epoch 320/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2415 - accuracy: 0.1307 - val_loss: 2.1189 - val_accuracy: 0.3494\n",
            "Epoch 321/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2416 - accuracy: 0.1333 - val_loss: 1.8860 - val_accuracy: 0.4952\n",
            "Epoch 322/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2426 - accuracy: 0.1321 - val_loss: 1.9505 - val_accuracy: 0.2974\n",
            "Epoch 323/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2416 - accuracy: 0.1311 - val_loss: 2.1008 - val_accuracy: 0.3593\n",
            "Epoch 324/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2405 - accuracy: 0.1322 - val_loss: 2.4190 - val_accuracy: 0.2952\n",
            "Epoch 325/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2434 - accuracy: 0.1371 - val_loss: 1.5431 - val_accuracy: 0.6105\n",
            "Epoch 326/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2401 - accuracy: 0.1275 - val_loss: 1.9107 - val_accuracy: 0.3918\n",
            "Epoch 327/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2410 - accuracy: 0.1324 - val_loss: 1.8730 - val_accuracy: 0.4139\n",
            "Epoch 328/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2406 - accuracy: 0.1346 - val_loss: 1.8121 - val_accuracy: 0.3967\n",
            "Epoch 329/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2413 - accuracy: 0.1322 - val_loss: 2.1670 - val_accuracy: 0.4498\n",
            "Epoch 330/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2416 - accuracy: 0.1315 - val_loss: 1.9166 - val_accuracy: 0.3841\n",
            "Epoch 331/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2395 - accuracy: 0.1321 - val_loss: 1.9445 - val_accuracy: 0.3200\n",
            "Epoch 332/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2429 - accuracy: 0.1275 - val_loss: 2.0300 - val_accuracy: 0.4784\n",
            "Epoch 333/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2399 - accuracy: 0.1309 - val_loss: 2.1363 - val_accuracy: 0.4261\n",
            "Epoch 334/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2398 - accuracy: 0.1301 - val_loss: 2.0785 - val_accuracy: 0.4055\n",
            "Epoch 335/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2413 - accuracy: 0.1312 - val_loss: 1.5318 - val_accuracy: 0.5235\n",
            "Epoch 336/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2408 - accuracy: 0.1332 - val_loss: 2.3285 - val_accuracy: 0.3967\n",
            "Epoch 337/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2432 - accuracy: 0.1385 - val_loss: 1.7633 - val_accuracy: 0.3887\n",
            "Epoch 338/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2416 - accuracy: 0.1314 - val_loss: 2.2039 - val_accuracy: 0.4895\n",
            "Epoch 339/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2406 - accuracy: 0.1311 - val_loss: 1.6479 - val_accuracy: 0.5250\n",
            "Epoch 340/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2412 - accuracy: 0.1346 - val_loss: 2.6000 - val_accuracy: 0.3100\n",
            "Epoch 341/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2399 - accuracy: 0.1346 - val_loss: 2.1039 - val_accuracy: 0.3429\n",
            "Epoch 342/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2411 - accuracy: 0.1275 - val_loss: 1.6306 - val_accuracy: 0.5391\n",
            "Epoch 343/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2395 - accuracy: 0.1341 - val_loss: 1.9585 - val_accuracy: 0.4227\n",
            "Epoch 344/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2417 - accuracy: 0.1341 - val_loss: 1.9768 - val_accuracy: 0.4200\n",
            "Epoch 345/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2419 - accuracy: 0.1295 - val_loss: 1.7366 - val_accuracy: 0.5311\n",
            "Epoch 346/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2402 - accuracy: 0.1342 - val_loss: 1.8271 - val_accuracy: 0.4826\n",
            "Epoch 347/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2398 - accuracy: 0.1315 - val_loss: 1.9452 - val_accuracy: 0.4635\n",
            "Epoch 348/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2415 - accuracy: 0.1282 - val_loss: 1.8363 - val_accuracy: 0.4040\n",
            "Epoch 349/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2406 - accuracy: 0.1349 - val_loss: 1.9769 - val_accuracy: 0.4643\n",
            "Epoch 350/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2401 - accuracy: 0.1322 - val_loss: 1.8314 - val_accuracy: 0.4494\n",
            "Epoch 351/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2399 - accuracy: 0.1290 - val_loss: 2.2116 - val_accuracy: 0.2822\n",
            "Epoch 352/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2407 - accuracy: 0.1275 - val_loss: 1.8783 - val_accuracy: 0.4318\n",
            "Epoch 353/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2408 - accuracy: 0.1278 - val_loss: 1.3226 - val_accuracy: 0.4884\n",
            "Epoch 354/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2418 - accuracy: 0.1306 - val_loss: 1.6683 - val_accuracy: 0.5071\n",
            "Epoch 355/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2388 - accuracy: 0.1337 - val_loss: 2.0895 - val_accuracy: 0.3498\n",
            "Epoch 356/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2402 - accuracy: 0.1296 - val_loss: 1.9124 - val_accuracy: 0.3902\n",
            "Epoch 357/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2422 - accuracy: 0.1318 - val_loss: 1.8586 - val_accuracy: 0.3658\n",
            "Epoch 358/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2400 - accuracy: 0.1338 - val_loss: 1.6316 - val_accuracy: 0.3990\n",
            "Epoch 359/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2406 - accuracy: 0.1317 - val_loss: 2.0053 - val_accuracy: 0.3467\n",
            "Epoch 360/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2398 - accuracy: 0.1308 - val_loss: 2.0100 - val_accuracy: 0.4234\n",
            "Epoch 361/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2413 - accuracy: 0.1275 - val_loss: 2.1253 - val_accuracy: 0.3452\n",
            "Epoch 362/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2394 - accuracy: 0.1288 - val_loss: 2.4169 - val_accuracy: 0.3681\n",
            "Epoch 363/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2416 - accuracy: 0.1356 - val_loss: 2.2882 - val_accuracy: 0.2730\n",
            "Epoch 364/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2413 - accuracy: 0.1284 - val_loss: 1.9715 - val_accuracy: 0.4341\n",
            "Epoch 365/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2398 - accuracy: 0.1313 - val_loss: 1.8683 - val_accuracy: 0.4391\n",
            "Epoch 366/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2397 - accuracy: 0.1329 - val_loss: 2.0524 - val_accuracy: 0.3330\n",
            "Epoch 367/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2414 - accuracy: 0.1292 - val_loss: 1.9146 - val_accuracy: 0.3566\n",
            "Epoch 368/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2397 - accuracy: 0.1294 - val_loss: 2.0655 - val_accuracy: 0.3085\n",
            "Epoch 369/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2400 - accuracy: 0.1270 - val_loss: 2.1769 - val_accuracy: 0.3333\n",
            "Epoch 370/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2408 - accuracy: 0.1336 - val_loss: 1.9609 - val_accuracy: 0.4387\n",
            "Epoch 371/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2402 - accuracy: 0.1306 - val_loss: 1.8126 - val_accuracy: 0.3085\n",
            "Epoch 372/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2400 - accuracy: 0.1294 - val_loss: 1.8479 - val_accuracy: 0.4215\n",
            "Epoch 373/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2415 - accuracy: 0.1358 - val_loss: 1.9886 - val_accuracy: 0.3807\n",
            "Epoch 374/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2397 - accuracy: 0.1378 - val_loss: 1.5712 - val_accuracy: 0.4234\n",
            "Epoch 375/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2394 - accuracy: 0.1279 - val_loss: 2.2765 - val_accuracy: 0.3360\n",
            "Epoch 376/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2407 - accuracy: 0.1330 - val_loss: 1.9967 - val_accuracy: 0.2936\n",
            "Epoch 377/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2402 - accuracy: 0.1301 - val_loss: 1.8371 - val_accuracy: 0.3849\n",
            "Epoch 378/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2402 - accuracy: 0.1311 - val_loss: 1.9148 - val_accuracy: 0.4066\n",
            "Epoch 379/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2403 - accuracy: 0.1321 - val_loss: 1.5360 - val_accuracy: 0.4147\n",
            "Epoch 380/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2412 - accuracy: 0.1400 - val_loss: 1.6851 - val_accuracy: 0.3536\n",
            "Epoch 381/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2386 - accuracy: 0.1294 - val_loss: 2.3019 - val_accuracy: 0.4181\n",
            "Epoch 382/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2412 - accuracy: 0.1307 - val_loss: 1.9519 - val_accuracy: 0.4601\n",
            "Epoch 383/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2403 - accuracy: 0.1305 - val_loss: 2.1443 - val_accuracy: 0.3135\n",
            "Epoch 384/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2415 - accuracy: 0.1253 - val_loss: 1.9980 - val_accuracy: 0.3612\n",
            "Epoch 385/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2400 - accuracy: 0.1282 - val_loss: 2.0485 - val_accuracy: 0.4231\n",
            "Epoch 386/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2397 - accuracy: 0.1319 - val_loss: 1.7793 - val_accuracy: 0.3669\n",
            "Epoch 387/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2417 - accuracy: 0.1324 - val_loss: 1.7966 - val_accuracy: 0.3677\n",
            "Epoch 388/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2403 - accuracy: 0.1330 - val_loss: 1.7722 - val_accuracy: 0.3520\n",
            "Epoch 389/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2399 - accuracy: 0.1334 - val_loss: 2.3342 - val_accuracy: 0.2776\n",
            "Epoch 390/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2402 - accuracy: 0.1335 - val_loss: 2.1832 - val_accuracy: 0.4265\n",
            "Epoch 391/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2398 - accuracy: 0.1294 - val_loss: 1.8682 - val_accuracy: 0.3597\n",
            "Epoch 392/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2397 - accuracy: 0.1305 - val_loss: 2.3237 - val_accuracy: 0.3669\n",
            "Epoch 393/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2415 - accuracy: 0.1284 - val_loss: 1.9189 - val_accuracy: 0.4036\n",
            "Epoch 394/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2403 - accuracy: 0.1340 - val_loss: 2.1659 - val_accuracy: 0.3658\n",
            "Epoch 395/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2390 - accuracy: 0.1251 - val_loss: 1.9991 - val_accuracy: 0.3990\n",
            "Epoch 396/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2409 - accuracy: 0.1346 - val_loss: 2.1921 - val_accuracy: 0.4330\n",
            "Epoch 397/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2413 - accuracy: 0.1270 - val_loss: 2.1995 - val_accuracy: 0.4066\n",
            "Epoch 398/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2410 - accuracy: 0.1311 - val_loss: 2.0457 - val_accuracy: 0.4002\n",
            "Epoch 399/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2415 - accuracy: 0.1311 - val_loss: 1.7575 - val_accuracy: 0.3990\n",
            "Epoch 400/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2409 - accuracy: 0.1389 - val_loss: 2.0106 - val_accuracy: 0.3532\n",
            "Epoch 401/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2393 - accuracy: 0.1322 - val_loss: 1.6689 - val_accuracy: 0.4273\n",
            "Epoch 402/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2412 - accuracy: 0.1313 - val_loss: 2.0072 - val_accuracy: 0.4551\n",
            "Epoch 403/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2404 - accuracy: 0.1325 - val_loss: 2.2197 - val_accuracy: 0.3769\n",
            "Epoch 404/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2396 - accuracy: 0.1333 - val_loss: 1.9666 - val_accuracy: 0.4716\n",
            "Epoch 405/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2415 - accuracy: 0.1323 - val_loss: 1.6691 - val_accuracy: 0.3986\n",
            "Epoch 406/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2418 - accuracy: 0.1299 - val_loss: 1.7839 - val_accuracy: 0.4502\n",
            "Epoch 407/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2399 - accuracy: 0.1296 - val_loss: 2.2986 - val_accuracy: 0.3826\n",
            "Epoch 408/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2387 - accuracy: 0.1290 - val_loss: 2.0552 - val_accuracy: 0.3837\n",
            "Epoch 409/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2406 - accuracy: 0.1313 - val_loss: 1.9899 - val_accuracy: 0.4723\n",
            "Epoch 410/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2398 - accuracy: 0.1303 - val_loss: 1.6601 - val_accuracy: 0.4746\n",
            "Epoch 411/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2395 - accuracy: 0.1300 - val_loss: 1.8265 - val_accuracy: 0.5128\n",
            "Epoch 412/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2396 - accuracy: 0.1375 - val_loss: 1.7294 - val_accuracy: 0.4765\n",
            "Epoch 413/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2398 - accuracy: 0.1321 - val_loss: 1.7864 - val_accuracy: 0.3673\n",
            "Epoch 414/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2385 - accuracy: 0.1315 - val_loss: 1.8308 - val_accuracy: 0.5613\n",
            "Epoch 415/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2415 - accuracy: 0.1284 - val_loss: 1.7454 - val_accuracy: 0.4227\n",
            "Epoch 416/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2402 - accuracy: 0.1352 - val_loss: 2.0002 - val_accuracy: 0.4307\n",
            "Epoch 417/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2405 - accuracy: 0.1345 - val_loss: 2.1826 - val_accuracy: 0.4330\n",
            "Epoch 418/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2420 - accuracy: 0.1330 - val_loss: 1.8846 - val_accuracy: 0.4887\n",
            "Epoch 419/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2400 - accuracy: 0.1315 - val_loss: 2.5340 - val_accuracy: 0.4666\n",
            "Epoch 420/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2406 - accuracy: 0.1338 - val_loss: 1.5415 - val_accuracy: 0.4926\n",
            "Epoch 421/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2397 - accuracy: 0.1356 - val_loss: 1.9557 - val_accuracy: 0.4635\n",
            "Epoch 422/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2396 - accuracy: 0.1313 - val_loss: 2.0945 - val_accuracy: 0.4212\n",
            "Epoch 423/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2391 - accuracy: 0.1313 - val_loss: 2.0841 - val_accuracy: 0.3482\n",
            "Epoch 424/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2406 - accuracy: 0.1319 - val_loss: 2.0102 - val_accuracy: 0.3433\n",
            "Epoch 425/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2394 - accuracy: 0.1299 - val_loss: 1.6525 - val_accuracy: 0.3669\n",
            "Epoch 426/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2407 - accuracy: 0.1300 - val_loss: 1.9150 - val_accuracy: 0.4185\n",
            "Epoch 427/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2403 - accuracy: 0.1298 - val_loss: 2.0319 - val_accuracy: 0.3841\n",
            "Epoch 428/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2395 - accuracy: 0.1290 - val_loss: 1.8078 - val_accuracy: 0.3433\n",
            "Epoch 429/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2414 - accuracy: 0.1280 - val_loss: 1.9968 - val_accuracy: 0.4066\n",
            "Epoch 430/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2386 - accuracy: 0.1263 - val_loss: 2.1304 - val_accuracy: 0.3616\n",
            "Epoch 431/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2406 - accuracy: 0.1253 - val_loss: 1.8360 - val_accuracy: 0.3681\n",
            "Epoch 432/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2403 - accuracy: 0.1339 - val_loss: 2.0278 - val_accuracy: 0.4639\n",
            "Epoch 433/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2397 - accuracy: 0.1302 - val_loss: 2.0137 - val_accuracy: 0.3746\n",
            "Epoch 434/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2390 - accuracy: 0.1265 - val_loss: 1.7077 - val_accuracy: 0.4448\n",
            "Epoch 435/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2400 - accuracy: 0.1320 - val_loss: 2.4079 - val_accuracy: 0.3410\n",
            "Epoch 436/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2408 - accuracy: 0.1346 - val_loss: 2.4528 - val_accuracy: 0.2921\n",
            "Epoch 437/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2395 - accuracy: 0.1328 - val_loss: 1.6715 - val_accuracy: 0.4303\n",
            "Epoch 438/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2388 - accuracy: 0.1294 - val_loss: 1.9563 - val_accuracy: 0.3429\n",
            "Epoch 439/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2399 - accuracy: 0.1259 - val_loss: 1.7103 - val_accuracy: 0.4666\n",
            "Epoch 440/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2396 - accuracy: 0.1307 - val_loss: 1.8978 - val_accuracy: 0.4212\n",
            "Epoch 441/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2399 - accuracy: 0.1301 - val_loss: 2.3158 - val_accuracy: 0.3944\n",
            "Epoch 442/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2401 - accuracy: 0.1315 - val_loss: 2.2907 - val_accuracy: 0.4051\n",
            "Epoch 443/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2417 - accuracy: 0.1330 - val_loss: 1.8681 - val_accuracy: 0.3902\n",
            "Epoch 444/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2380 - accuracy: 0.1266 - val_loss: 2.1599 - val_accuracy: 0.3192\n",
            "Epoch 445/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2382 - accuracy: 0.1292 - val_loss: 1.9863 - val_accuracy: 0.5430\n",
            "Epoch 446/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2406 - accuracy: 0.1272 - val_loss: 1.6424 - val_accuracy: 0.3471\n",
            "Epoch 447/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2395 - accuracy: 0.1309 - val_loss: 2.0158 - val_accuracy: 0.3608\n",
            "Epoch 448/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2404 - accuracy: 0.1321 - val_loss: 1.8337 - val_accuracy: 0.4261\n",
            "Epoch 449/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2387 - accuracy: 0.1298 - val_loss: 1.6626 - val_accuracy: 0.5773\n",
            "Epoch 450/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2406 - accuracy: 0.1314 - val_loss: 2.2824 - val_accuracy: 0.3898\n",
            "Epoch 451/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2401 - accuracy: 0.1341 - val_loss: 2.3383 - val_accuracy: 0.5036\n",
            "Epoch 452/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2399 - accuracy: 0.1297 - val_loss: 2.2170 - val_accuracy: 0.4131\n",
            "Epoch 453/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2392 - accuracy: 0.1327 - val_loss: 1.8960 - val_accuracy: 0.5128\n",
            "Epoch 454/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2396 - accuracy: 0.1294 - val_loss: 1.6256 - val_accuracy: 0.4051\n",
            "Epoch 455/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2401 - accuracy: 0.1319 - val_loss: 2.0125 - val_accuracy: 0.4620\n",
            "Epoch 456/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2389 - accuracy: 0.1342 - val_loss: 2.3527 - val_accuracy: 0.5452\n",
            "Epoch 457/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2392 - accuracy: 0.1319 - val_loss: 2.0606 - val_accuracy: 0.4234\n",
            "Epoch 458/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2397 - accuracy: 0.1346 - val_loss: 1.8665 - val_accuracy: 0.5048\n",
            "Epoch 459/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2401 - accuracy: 0.1290 - val_loss: 2.0475 - val_accuracy: 0.4238\n",
            "Epoch 460/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2392 - accuracy: 0.1311 - val_loss: 1.8882 - val_accuracy: 0.3738\n",
            "Epoch 461/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2398 - accuracy: 0.1319 - val_loss: 1.7849 - val_accuracy: 0.3940\n",
            "Epoch 462/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2387 - accuracy: 0.1315 - val_loss: 1.9853 - val_accuracy: 0.4257\n",
            "Epoch 463/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2416 - accuracy: 0.1369 - val_loss: 2.0910 - val_accuracy: 0.3822\n",
            "Epoch 464/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2406 - accuracy: 0.1284 - val_loss: 1.9318 - val_accuracy: 0.5475\n",
            "Epoch 465/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2406 - accuracy: 0.1255 - val_loss: 1.7073 - val_accuracy: 0.3349\n",
            "Epoch 466/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2403 - accuracy: 0.1327 - val_loss: 1.8132 - val_accuracy: 0.4364\n",
            "Epoch 467/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2375 - accuracy: 0.1309 - val_loss: 1.7627 - val_accuracy: 0.4945\n",
            "Epoch 468/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2398 - accuracy: 0.1296 - val_loss: 1.8870 - val_accuracy: 0.4624\n",
            "Epoch 469/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2393 - accuracy: 0.1295 - val_loss: 1.8360 - val_accuracy: 0.4231\n",
            "Epoch 470/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2395 - accuracy: 0.1363 - val_loss: 1.8414 - val_accuracy: 0.4303\n",
            "Epoch 471/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2386 - accuracy: 0.1367 - val_loss: 1.5171 - val_accuracy: 0.5319\n",
            "Epoch 472/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2380 - accuracy: 0.1279 - val_loss: 1.8709 - val_accuracy: 0.4616\n",
            "Epoch 473/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2402 - accuracy: 0.1317 - val_loss: 1.9842 - val_accuracy: 0.5220\n",
            "Epoch 474/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2405 - accuracy: 0.1346 - val_loss: 1.7094 - val_accuracy: 0.5074\n",
            "Epoch 475/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2397 - accuracy: 0.1330 - val_loss: 2.1360 - val_accuracy: 0.3444\n",
            "Epoch 476/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2398 - accuracy: 0.1319 - val_loss: 2.4232 - val_accuracy: 0.4181\n",
            "Epoch 477/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2390 - accuracy: 0.1318 - val_loss: 2.0452 - val_accuracy: 0.3582\n",
            "Epoch 478/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2387 - accuracy: 0.1340 - val_loss: 2.3742 - val_accuracy: 0.4280\n",
            "Epoch 479/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2417 - accuracy: 0.1305 - val_loss: 1.6848 - val_accuracy: 0.5410\n",
            "Epoch 480/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2382 - accuracy: 0.1330 - val_loss: 1.8437 - val_accuracy: 0.3505\n",
            "Epoch 481/500\n",
            "464/464 [==============================] - 1s 2ms/step - loss: 0.2395 - accuracy: 0.1257 - val_loss: 1.8362 - val_accuracy: 0.4410\n",
            "Epoch 482/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2390 - accuracy: 0.1296 - val_loss: 1.9135 - val_accuracy: 0.4063\n",
            "Epoch 483/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2391 - accuracy: 0.1330 - val_loss: 1.9994 - val_accuracy: 0.3933\n",
            "Epoch 484/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2377 - accuracy: 0.1264 - val_loss: 1.9156 - val_accuracy: 0.4380\n",
            "Epoch 485/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2390 - accuracy: 0.1318 - val_loss: 1.6418 - val_accuracy: 0.5567\n",
            "Epoch 486/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2403 - accuracy: 0.1298 - val_loss: 2.0579 - val_accuracy: 0.4448\n",
            "Epoch 487/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2380 - accuracy: 0.1293 - val_loss: 1.8983 - val_accuracy: 0.5078\n",
            "Epoch 488/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2381 - accuracy: 0.1323 - val_loss: 1.8715 - val_accuracy: 0.3475\n",
            "Epoch 489/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2390 - accuracy: 0.1302 - val_loss: 1.8437 - val_accuracy: 0.3692\n",
            "Epoch 490/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2380 - accuracy: 0.1292 - val_loss: 2.0621 - val_accuracy: 0.2833\n",
            "Epoch 491/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2380 - accuracy: 0.1327 - val_loss: 1.7317 - val_accuracy: 0.4662\n",
            "Epoch 492/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2401 - accuracy: 0.1305 - val_loss: 1.7415 - val_accuracy: 0.3868\n",
            "Epoch 493/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2385 - accuracy: 0.1308 - val_loss: 1.9872 - val_accuracy: 0.4177\n",
            "Epoch 494/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2391 - accuracy: 0.1344 - val_loss: 1.7823 - val_accuracy: 0.4559\n",
            "Epoch 495/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2387 - accuracy: 0.1317 - val_loss: 2.1767 - val_accuracy: 0.4758\n",
            "Epoch 496/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2388 - accuracy: 0.1344 - val_loss: 1.7824 - val_accuracy: 0.4780\n",
            "Epoch 497/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2388 - accuracy: 0.1307 - val_loss: 2.0012 - val_accuracy: 0.4143\n",
            "Epoch 498/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2383 - accuracy: 0.1317 - val_loss: 2.1000 - val_accuracy: 0.3318\n",
            "Epoch 499/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2395 - accuracy: 0.1313 - val_loss: 1.9861 - val_accuracy: 0.4322\n",
            "Epoch 500/500\n",
            "464/464 [==============================] - 1s 3ms/step - loss: 0.2394 - accuracy: 0.1277 - val_loss: 1.8096 - val_accuracy: 0.4059\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6fb978ce50>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = (model.predict(X_test1) > 0.5).astype(int)\n",
        "for i in range(100):\n",
        "\tprint('%s => %s (expected %s)' % (X_test1[i].tolist(), predictions[i].tolist(), y_test1[i].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSf5tw7sBH6U",
        "outputId": "a5f1c8a6-2129-4ea6-d0ae-3ba67481286c"
      },
      "id": "ZSf5tw7sBH6U",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[282.28, 2019.0, 1.0, 1.0, 0.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[248.73000000000002, 2019.0, 1.0, 1.0, 1.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[266.34000000000003, 2019.0, 1.0, 1.0, 2.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[264.995, 2019.0, 1.0, 1.0, 3.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[299.005, 2019.0, 1.0, 1.0, 4.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[248.775, 2019.0, 1.0, 1.0, 5.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[282.33, 2019.0, 1.0, 1.0, 6.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[283.04, 2019.0, 1.0, 1.0, 7.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[253.05, 2019.0, 1.0, 1.0, 8.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[271.79, 2019.0, 1.0, 1.0, 9.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[302.79, 2019.0, 1.0, 1.0, 10.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 0.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[236.27, 2019.0, 1.0, 1.0, 11.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[251.84, 2019.0, 1.0, 1.0, 12.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[267.79, 2019.0, 1.0, 1.0, 13.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[218.53, 2019.0, 1.0, 1.0, 14.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[217.31, 2019.0, 1.0, 1.0, 15.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[269.22, 2019.0, 1.0, 1.0, 16.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[219.01, 2019.0, 1.0, 1.0, 17.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[254.79, 2019.0, 1.0, 1.0, 18.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[272.52, 2019.0, 1.0, 1.0, 19.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[205.06, 2019.0, 1.0, 1.0, 20.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[237.29, 2019.0, 1.0, 1.0, 21.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[286.86, 2019.0, 1.0, 1.0, 22.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[251.5, 2019.0, 1.0, 1.0, 23.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[215.51999999999998, 2019.0, 1.0, 2.0, 0.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[249.28, 2019.0, 1.0, 2.0, 1.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[249.01, 2019.0, 1.0, 2.0, 2.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[215.02, 2019.0, 1.0, 2.0, 3.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[266.24, 2019.0, 1.0, 2.0, 4.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[216.233, 2019.0, 1.0, 2.0, 5.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[232.04, 2019.0, 1.0, 2.0, 6.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[266.99, 2019.0, 1.0, 2.0, 7.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[253.26999999999998, 2019.0, 1.0, 2.0, 8.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[256.28, 2019.0, 1.0, 2.0, 9.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[253.22, 2019.0, 1.0, 2.0, 10.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[218.47, 2019.0, 1.0, 2.0, 11.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[221.73000000000002, 2019.0, 1.0, 2.0, 12.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[235.01, 2019.0, 1.0, 2.0, 13.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[165.49, 2019.0, 1.0, 2.0, 14.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[214.03, 2019.0, 1.0, 2.0, 15.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[184.01, 2019.0, 1.0, 2.0, 16.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 0.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[201.76999999999998, 2019.0, 1.0, 2.0, 17.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[220.8, 2019.0, 1.0, 2.0, 18.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[209.27, 2019.0, 1.0, 2.0, 19.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[276.01, 2019.0, 1.0, 2.0, 20.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[258.18, 2019.0, 1.0, 2.0, 21.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[223.53, 2019.0, 1.0, 2.0, 22.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[272.29, 2019.0, 1.0, 2.0, 23.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[252.24, 2019.0, 1.0, 3.0, 0.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[235.23000000000002, 2019.0, 1.0, 3.0, 1.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[285.29, 2019.0, 1.0, 3.0, 2.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[253.01, 2019.0, 1.0, 3.0, 3.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[252.78, 2019.0, 1.0, 3.0, 4.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 0.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[302.51, 2019.0, 1.0, 3.0, 5.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[268.233, 2019.0, 1.0, 3.0, 6.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[270.48, 2019.0, 1.0, 3.0, 7.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[308.83, 2019.0, 1.0, 3.0, 8.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[298.24, 2019.0, 1.0, 3.0, 9.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[501.47, 2019.0, 1.0, 3.0, 10.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[719.95, 2019.0, 1.0, 3.0, 11.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[854.0, 2019.0, 1.0, 3.0, 12.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[857.0, 2019.0, 1.0, 3.0, 13.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[733.9, 2019.0, 1.0, 3.0, 14.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[762.0, 2019.0, 1.0, 3.0, 15.0] => [1, 1, 1, 1, 1, 1] (expected [1.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[717.8, 2019.0, 1.0, 3.0, 16.0] => [1, 1, 1, 1, 1, 1] (expected [1.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[655.29, 2019.0, 1.0, 3.0, 17.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[658.96, 2019.0, 1.0, 3.0, 18.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[662.0, 2019.0, 1.0, 3.0, 19.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[656.51, 2019.0, 1.0, 3.0, 20.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[615.79, 2019.0, 1.0, 3.0, 21.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[327.81, 2019.0, 1.0, 3.0, 22.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[359.75, 2019.0, 1.0, 3.0, 23.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[424.08, 2019.0, 1.0, 4.0, 0.0] => [0, 1, 0, 1, 1, 1] (expected [1.0, 1.0, 0.0, 0.0, 1.0, 1.0])\n",
            "[450.9, 2019.0, 1.0, 4.0, 1.0] => [1, 1, 0, 1, 1, 1] (expected [1.0, 1.0, 0.0, 0.0, 1.0, 1.0])\n",
            "[389.3, 2019.0, 1.0, 4.0, 2.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 1.0, 1.0])\n",
            "[389.775, 2019.0, 1.0, 4.0, 3.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 1.0, 1.0])\n",
            "[424.73, 2019.0, 1.0, 4.0, 4.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 1.0, 1.0])\n",
            "[614.08, 2019.0, 1.0, 4.0, 5.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[595.53, 2019.0, 1.0, 4.0, 6.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 1.0, 1.0])\n",
            "[681.28, 2019.0, 1.0, 4.0, 7.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 1.0, 1.0])\n",
            "[568.74, 2019.0, 1.0, 4.0, 8.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[768.0, 2019.0, 1.0, 4.0, 9.0] => [1, 1, 1, 1, 1, 1] (expected [1.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[703.96, 2019.0, 1.0, 4.0, 10.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[872.23, 2019.0, 1.0, 4.0, 11.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[902.6800000000001, 2019.0, 1.0, 4.0, 12.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[806.5, 2019.0, 1.0, 4.0, 13.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[736.8, 2019.0, 1.0, 4.0, 14.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[616.0, 2019.0, 1.0, 4.0, 15.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[408.19, 2019.0, 1.0, 4.0, 16.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[588.4, 2019.0, 1.0, 4.0, 17.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[581.76, 2019.0, 1.0, 4.0, 18.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 1.0, 1.0])\n",
            "[405.5, 2019.0, 1.0, 4.0, 19.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[500.24, 2019.0, 1.0, 4.0, 20.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[392.025, 2019.0, 1.0, 4.0, 21.0] => [1, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[186.23, 2019.0, 1.0, 4.0, 22.0] => [0, 1, 1, 1, 1, 1] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[151.04, 2019.0, 1.0, 4.0, 23.0] => [0, 1, 1, 1, 1, 0] (expected [0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
            "[231.96, 2019.0, 1.0, 5.0, 0.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[184.07, 2019.0, 1.0, 5.0, 1.0] => [0, 1, 0, 1, 1, 1] (expected [0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[237.19, 2019.0, 1.0, 5.0, 2.0] => [0, 1, 0, 1, 1, 1] (expected [1.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
            "[330.23799999999994, 2019.0, 1.0, 5.0, 3.0] => [0, 1, 0, 1, 1, 1] (expected [1.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['Ventilation', 'Soket Plugs', 'Lighting', 'Other Electricity', 'Cooling', 'Heating']\n",
        "print(classification_report(y_test1, predictions, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVMivvbKsxtf",
        "outputId": "cc4c2338-6e42-48c5-df1d-2561cf0ab904"
      },
      "id": "QVMivvbKsxtf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "      Ventilation       0.73      0.85      0.78      3912\n",
            "      Soket Plugs       0.93      0.94      0.93      8164\n",
            "         Lighting       0.83      0.76      0.79      5362\n",
            "Other Electricity       0.71      0.90      0.79      5572\n",
            "          Cooling       0.72      0.95      0.82      6324\n",
            "          Heating       0.82      0.78      0.80      5012\n",
            "\n",
            "        micro avg       0.79      0.87      0.83     34346\n",
            "        macro avg       0.79      0.86      0.82     34346\n",
            "     weighted avg       0.80      0.87      0.83     34346\n",
            "      samples avg       0.77      0.86      0.79     34346\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qK9jxA8ssxcC"
      },
      "id": "qK9jxA8ssxcC"
    },
    {
      "cell_type": "code",
      "source": [
        "# vent_pred = pred[:,[0,]]\n",
        "# vent_pred = np.asarray(vent_pred).reshape(-1)\n",
        "\n",
        "# vent_test = y_test1[:,[0,]]\n",
        "# vent_test = np.asarray(vent_test).reshape(-1)"
      ],
      "metadata": {
        "id": "-Mc13r0ccSMQ"
      },
      "id": "-Mc13r0ccSMQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(vent_pred, label='Predicted Value') #plot the loss\n",
        "# plt.plot(vent_test, label='True Value') #plot the validation loss\n",
        "# plt.legend(['Predicted Value', 'True Value'], loc='upper right')\n",
        "# plt.title('Graph for Ventillation Prediction')"
      ],
      "metadata": {
        "id": "n_lJS-rkcmDu"
      },
      "id": "n_lJS-rkcmDu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import mean_absolute_error as mae\n",
        "\n",
        "# print(\"Mean Absolute Error is: \", mae(vent_test,vent_pred))"
      ],
      "metadata": {
        "id": "SceFKLxnc4ZE"
      },
      "id": "SceFKLxnc4ZE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plug_pred = pred[:,[1,]]\n",
        "# plug_pred = np.asarray(plug_pred).reshape(-1)\n",
        "\n",
        "# plug_test = y_test1[:,[1,]]\n",
        "# plug_test = np.asarray(plug_test).reshape(-1)"
      ],
      "metadata": {
        "id": "m0zEyDOoYzaK"
      },
      "id": "m0zEyDOoYzaK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(plug_pred, label='Predicted Value') #plot the loss\n",
        "# plt.plot(plug_test, label='True Value') #plot the validation loss\n",
        "# plt.legend(['Predicted Value', 'True Value'], loc='upper right')\n",
        "# plt.title('Graph for Socket Plug Prediction')"
      ],
      "metadata": {
        "id": "oVYZg0ZwY2z3"
      },
      "id": "oVYZg0ZwY2z3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import mean_absolute_error as mae\n",
        "\n",
        "# print(\"Mean Absolute Error is: \", mae(plug_test,plug_pred))"
      ],
      "metadata": {
        "id": "o87ElRwOY-0F"
      },
      "id": "o87ElRwOY-0F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# light_pred = pred[:,[2,]]\n",
        "# light_pred = np.asarray(light_pred).reshape(-1)\n",
        "\n",
        "# light_test = y_test1[:,[2,]]\n",
        "# light_test = np.asarray(light_test).reshape(-1)"
      ],
      "metadata": {
        "id": "mwj0_BHIeGUi"
      },
      "id": "mwj0_BHIeGUi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(light_pred, label='Predicted Value') #plot the loss\n",
        "# plt.plot(light_test, label='True Value') #plot the validation loss\n",
        "# plt.legend(['Predicted Value', 'True Value'], loc='upper right')\n",
        "# plt.title('Graph for Lighting Prediction')"
      ],
      "metadata": {
        "id": "EpLtYOuYeQnI"
      },
      "id": "EpLtYOuYeQnI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import mean_absolute_error as mae\n",
        "\n",
        "# print(\"Mean Absolute Error is: \", mae(light_test,light_pred))"
      ],
      "metadata": {
        "id": "1nlAgxvIepNU"
      },
      "id": "1nlAgxvIepNU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# other_pred = pred[:,[3,]]\n",
        "# other_pred = np.asarray(other_pred).reshape(-1)\n",
        "\n",
        "# other_test = y_test1[:,[3,]]\n",
        "# other_test = np.asarray(other_test).reshape(-1)"
      ],
      "metadata": {
        "id": "s-SfKrLveS-9"
      },
      "id": "s-SfKrLveS-9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(other_pred, label='Predicted Value') #plot the loss\n",
        "# plt.plot(other_test, label='True Value') #plot the validation loss\n",
        "# plt.legend(['Predicted Value', 'True Value'], loc='upper right')\n",
        "# plt.title('Graph for Other Electricity Prediction')"
      ],
      "metadata": {
        "id": "23v9UWGheVue"
      },
      "id": "23v9UWGheVue",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import mean_absolute_error as mae\n",
        "\n",
        "# print(\"Mean Absolute Error is: \", mae(other_test,other_pred))"
      ],
      "metadata": {
        "id": "rmPrzP6LesbU"
      },
      "id": "rmPrzP6LesbU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cool_pred = pred[:,[4,]]\n",
        "# cool_pred = np.asarray(cool_pred).reshape(-1)\n",
        "\n",
        "# cool_test = y_test1[:,[4,]]\n",
        "# cool_test = np.asarray(cool_test).reshape(-1)"
      ],
      "metadata": {
        "id": "CjCVwYqceX-v"
      },
      "id": "CjCVwYqceX-v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(cool_pred, label='Predicted Value') #plot the loss\n",
        "# plt.plot(cool_test, label='True Value') #plot the validation loss\n",
        "# plt.legend(['Predicted Value', 'True Value'], loc='upper right')\n",
        "# plt.title('Graph for Cooling Prediction')"
      ],
      "metadata": {
        "id": "OwyGIMCyeaz_"
      },
      "id": "OwyGIMCyeaz_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import mean_absolute_error as mae\n",
        "\n",
        "# print(\"Mean Absolute Error is: \", mae(cool_test,cool_pred))"
      ],
      "metadata": {
        "id": "_EEfRwF9evux"
      },
      "id": "_EEfRwF9evux",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# heat_pred = pred[:,[5,]]\n",
        "# heat_pred = np.asarray(heat_pred).reshape(-1)\n",
        "\n",
        "# heat_test = y_test1[:,[5,]]\n",
        "# heat_test = np.asarray(heat_test).reshape(-1)"
      ],
      "metadata": {
        "id": "--LZih2Necvr"
      },
      "id": "--LZih2Necvr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(heat_pred, label='Predicted Value') #plot the loss\n",
        "# plt.plot(heat_test, label='True Value') #plot the validation loss\n",
        "# plt.legend(['Predicted Value', 'True Value'], loc='upper right')\n",
        "# plt.title('Graph for Heating Prediction')"
      ],
      "metadata": {
        "id": "pCXIDc3Zeeox"
      },
      "id": "pCXIDc3Zeeox",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import mean_absolute_error as mae\n",
        "\n",
        "# print(\"Mean Absolute Error is: \", mae(heat_test,heat_pred))"
      ],
      "metadata": {
        "id": "vYy8XfUweysW"
      },
      "id": "vYy8XfUweysW",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Applying Classification for Grenoble Dataset.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}